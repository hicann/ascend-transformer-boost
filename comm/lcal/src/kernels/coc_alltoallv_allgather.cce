#ifdef __DAV_C220_VEC__
#include <cstdio>

#include "coc_internal.cce"
#include "coc_comm_base.cce"
#include "kernel_operator.h"
using namespace AscendC;

template <bool HAVE_BIAS, typename T, typename MatType> 
class AllToAllvAllGather: public CocCommBase<T, MatType>{
public:
    __aicore__ explicit AllToAllvAllGather(){};
     inline __attribute__((always_inline)) __aicore__ void SetArgs(COC_ARGS_FUN(T)){
        CocCommBase<T, MatType>::SetArgs(COC_ARGS_CALL());
        preprocessor.SetArgs(PP_MATMUL_AIV_PADDING_ARGS_CALL());
        if constexpr (HAVE_BIAS) {
            add_bias_runner.SetArgs(PP_MATMUL_AIV_ADD_BIAS_ARGS_CALL());
        }
        m_align = Block512B<T>::AlignUp(m);
        k_align = Block512B<T>::AlignUp(k);
        n_align = Block512B<T>::AlignUp(n);
        
        AlignJudge(trans_a, trans_b, m, k, n, m_align, k_align, n_align, aligned_a, aligned_b);
        this->gm_out = aligned_a ? reinterpret_cast<__gm__ T *>(workspace_info.gm_a_align) : gm_a;
        this->gm_quant_scale = reinterpret_cast<__gm__ float32_t *>(gm_quant_scale);
        this -> expert_nums = local_expert_nums * EP;
        is_moe_averaged = 0;
        if(global_tokens_per_expert_matrix == nullptr) {
            is_moe_averaged = 1;
        }
        this -> global_tokens_per_expert_matrix = reinterpret_cast<__gm__ int32_t *>(global_tokens_per_expert_matrix);
        gm_a_pingpong_size = m0 * k_align * p_value * rank_size;
        if(dequant_granularity == QuantGranularity::PER_TOKEN) {
            int32_t output_num = m;
            if (!is_moe_averaged) {
                output_num = 0;
                for (int32_t i = 0 ; i < EP; i++) {
                    for (int32_t j = 0; j < local_expert_nums; j++) {
                        output_num += global_tokens_per_expert_matrix[i * expert_nums + j + rank * local_expert_nums];
                    }
                }
                if (maxOutputSize > 0 && output_num >= maxOutputSize) {
                    output_num = maxOutputSize;
                }
            }
            serial_pertoken_dequant_runner.SetArgs(reinterpret_cast<__gm__ MatType *>(gm_out), reinterpret_cast<__gm__ float32_t*>(workspace_info.gm_dequant_param), output_num, n, m0, n0);
        }
    }

    inline __attribute__((always_inline)) __aicore__ void ScaleAllToAll(){

        int32_t usable_buff = 200 * 1024 * 1024 / 4 / 2;
        int32_t max_move_num = usable_buff / rank_size;
        int32_t scale_pingpang_size = usable_buff;

        int32_t cal_count = 0;
        if(is_moe_averaged) {
            cal_count = DivCeil(m / EP, max_move_num);
        } else {
            for(int32_t ep_idx = 0; ep_idx < EP; ep_idx ++) {
                int32_t in_num = 0;
                int32_t out_num = 0;
                for(int32_t j = 0; j < local_expert_nums; j++) {
                    out_num += global_tokens_per_expert_matrix[rank * expert_nums + j + ep_idx * local_expert_nums];
                }
                for(int32_t j = 0; j < local_expert_nums; j++) {
                    in_num += global_tokens_per_expert_matrix[ep_idx * expert_nums + j + rank * local_expert_nums];//
                }
                cal_count = max(cal_count, max(in_num, out_num));
            }
            cal_count = DivCeil(cal_count, max_move_num);
        }

        PipeBarrier<PIPE_ALL>();

        int64_t sum_out = 0, sum_in = 0;
        int32_t received_loop_number = 0;
        int32_t ep_idx = real_core_idx;

        int32_t out_num, in_num;
        if(is_moe_averaged) {
            out_num = m / EP;
            in_num = m / EP;
        } else if(real_core_idx < rank_size){
            out_num = 0;
            in_num = 0;
            for(int32_t j = 0; j < local_expert_nums; j++) {
                out_num += global_tokens_per_expert_matrix[rank * expert_nums + j + real_core_idx * local_expert_nums];
            }
            for(int32_t j = 0; j < local_expert_nums; j ++) {
                in_num += global_tokens_per_expert_matrix[real_core_idx * expert_nums + rank * local_expert_nums + j];
            }
        }

        max_ub_ping_pong_size = max_ub_ping_pong_size / 2; //
        int32_t receive_expert_id = 0;
        int32_t receive_expert_token_nums;
        int32_t last_ep_local = 0;
        if (is_moe_averaged) {
            receive_expert_token_nums = m / EP / local_expert_nums;
            last_ep_local = (m / EP) * real_core_idx;
        } else if(real_core_idx < rank_size){
            receive_expert_token_nums = global_tokens_per_expert_matrix[real_core_idx * expert_nums + rank * local_expert_nums];
            for(int32_t i = 0; i < real_core_idx * local_expert_nums; i++) {
                last_ep_local += global_tokens_per_expert_matrix[rank * expert_nums + i];
            }
        }

        for(int32_t cal_idx = 0; cal_idx < cal_count; cal_idx ++) {
            int32_t flag_idx = cal_idx % MAX_BLOCK_COUNT;

            SetAndWaitAivSync(flag_idx);
            int32_t received_rank_num = 0;
            if (is_moe_averaged){
                received_rank_num = rank_size;
            } else {
                for(int32_t i = 0; i < EP; i++) {
                    int32_t in_num_tmp = 0;
                    for(int32_t j = 0; j < local_expert_nums; j++) {
                        in_num_tmp += global_tokens_per_expert_matrix[i * expert_nums + rank * local_expert_nums + j];//
                    }
                    if(cal_idx * max_move_num < in_num_tmp) {
                        received_rank_num += 1;
                    }
                }
            }

            received_loop_number += received_rank_num;

            if(real_core_idx < rank_size){
                if(real_core_idx == rank) {
                    SetBuffFlagByAdd(ctrl_flags_UB, (__gm__ int32_t *)buff[rank] + flag_offset + 
                        FLAG_TWO_IDX, FLAG_VALUE);
                }
                if(is_moe_averaged || cal_idx * max_move_num < out_num) { 
                    int32_t data_len = ((cal_idx + 1) * max_move_num >= out_num) ? (out_num - cal_idx * max_move_num) : max_move_num;
                    __gm__ float32_t *src_address;
                    __gm__ float32_t *dst_address = (__gm__ float32_t *)buff[real_core_idx] + flag_idx * scale_pingpang_size + max_move_num * rank;;
                    if (is_moe_averaged) {
                        src_address = gm_quant_scale + 1LL * last_ep_local + sum_out;
                    } else {
                        src_address = gm_quant_scale + 1LL * last_ep_local + sum_out;
                    }
                    CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + 
                        FLAG_TWO_IDX, FLAG_VALUE * (cal_idx + 1));
                    
                    SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                    SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3
                    MoveResultFromSrcToDst(src_address, dst_address, data_len, 0);
                    WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                    WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3

                    sum_out += data_len;
                    SetBuffFlagByAdd(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + 
                            FLAG_ADD_IDX, FLAG_VALUE);
                }
                CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[rank] + flag_offset + 
                    FLAG_ADD_IDX, FLAG_VALUE * received_loop_number);

                if(is_moe_averaged || cal_idx * max_move_num < in_num) {
                    int32_t data_len = ((cal_idx + 1) * max_move_num >= in_num) ? (in_num - cal_idx * max_move_num) : max_move_num;
                    __gm__ float32_t *src_address;
                    __gm__ float32_t *dst_address;
                    src_address = (__gm__ float32_t *)buff[rank] + flag_idx * scale_pingpang_size + max_move_num * real_core_idx;

                    while(receive_expert_id < local_expert_nums && data_len > 0) {
                        int32_t move_data_len;
                        if (data_len >= receive_expert_token_nums){
                            move_data_len = receive_expert_token_nums;
                        } else {
                            move_data_len = data_len;
                        }

                        if (is_moe_averaged) {
                            dst_address = reinterpret_cast<__gm__ float32_t *>(workspace_info.gm_dequant_param) + 
                                1LL * (m / local_expert_nums) * receive_expert_id + 1LL * (m / expert_nums) * real_core_idx + sum_in;
                        } else {
                            int32_t before_expert_sum = 0;
                            for(int32_t i = 0; i < receive_expert_id; i++){
                                for(int32_t j = 0; j < EP; j ++) {
                                    before_expert_sum += global_tokens_per_expert_matrix[j * expert_nums + i + rank * local_expert_nums];
                                }
                            }
                            int32_t before_rank_in_expert_sum = 0;
                            for(int32_t i = 0; i < real_core_idx; i++){
                                before_rank_in_expert_sum += global_tokens_per_expert_matrix[i * expert_nums + rank * local_expert_nums + receive_expert_id];
                            }
                            dst_address = reinterpret_cast<__gm__ float32_t *>(workspace_info.gm_dequant_param) + 
                                1LL * before_expert_sum + 1LL * before_rank_in_expert_sum + sum_in;
                        }

                        SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                        SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3
                        MoveResultFromSrcToDst(src_address, dst_address, move_data_len, 0);
                        WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                        WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3


                        if (data_len >= receive_expert_token_nums){
                            receive_expert_id += 1;
                            data_len -= receive_expert_token_nums;
                            if (receive_expert_id > local_expert_nums) {
                                break;
                            }
                            if (is_moe_averaged) {
                                receive_expert_token_nums = m / EP / local_expert_nums;
                            } else {
                                receive_expert_token_nums = global_tokens_per_expert_matrix[real_core_idx * expert_nums + receive_expert_id + rank * local_expert_nums];
                            }
                            sum_in = 0;
                        } else{
                            sum_in += data_len;
                            receive_expert_token_nums -= data_len;
                            data_len = 0;
                        }
                        src_address += move_data_len;
                    }
                }
            }
        }


        max_ub_ping_pong_size = max_ub_ping_pong_size * 2;

        if (real_core_idx < rank_size) {
            if(real_core_idx == rank) {
                SetBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[rank] + flag_offset + FLAG_TWO_IDX, 0);
            }
            CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + FLAG_TWO_IDX, 0);
        }
        PipeBarrier<PIPE_ALL>();
    }



    template <typename CommType>
    inline __attribute__((always_inline)) __aicore__ void MoveResultFromSrcToDst(__gm__ CommType *gm_src, __gm__ CommType *gm_dst,
                                                                                 int32_t len, bool is_align = true)
    {
        __ubuf__ CommType *output_UB_T[2] = {(__ubuf__ CommType *)(32), (__ubuf__ CommType *)(97440)};
        int32_t ping_pong_move_count = (len + max_ub_ping_pong_size - 1) / max_ub_ping_pong_size;
        for (int32_t move_idx = 0; move_idx < ping_pong_move_count; ++move_idx) {
            int32_t actual_move_size = max_ub_ping_pong_size;
            if (move_idx == ping_pong_move_count - 1) {
                actual_move_size = len - move_idx * max_ub_ping_pong_size;
            }
            auto event_id = (move_idx & 1) ? EVENT_ID0 : EVENT_ID1;
            auto ub_buff_st = (move_idx & 1) ? output_UB_T[0] : output_UB_T[1];
            WaitFlag<HardEvent::MTE3_MTE2>(event_id);
            if(is_align) {
                CopyGmToUbuf(ub_buff_st, gm_src, 1, actual_move_size * sizeof(CommType) / 32, 0, 0);
            } else {
                CopyGmToUbufAlignB16(ub_buff_st, gm_src, 1, actual_move_size * sizeof(CommType), 0, 0);
            }
            SetFlag<HardEvent::MTE2_MTE3>(event_id);
            WaitFlag<HardEvent::MTE2_MTE3>(event_id);
            if(is_align) {
                CopyUbufToGm(gm_dst, ub_buff_st, 1, actual_move_size * sizeof(CommType) / 32, 0, 0);
            } else {
                CopyUbufToGmAlignB16(gm_dst, ub_buff_st, 1, actual_move_size * sizeof(CommType), 0, 0);
            }
            gm_src += max_ub_ping_pong_size;
            gm_dst += max_ub_ping_pong_size;
            SetFlag<HardEvent::MTE3_MTE2>(event_id);
        }
    }

    inline __attribute__((always_inline)) __aicore__ void EndFlagsAndBias()
    {
        ResetIpcFlags(4);
        if (real_core_idx < rank_size) {
            CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + FLAG_ZERO_IDX, 0);
        }
        PipeBarrier<PIPE_ALL>();
        if constexpr (HAVE_BIAS) {
            add_bias_runner.Run();
        }
    }

inline __attribute__((always_inline)) __aicore__ void Run(){
        preprocessor.Run(local_expert_nums);
        int32_t comm_m = p_value * m0;
        int32_t comm_count;
        if (is_moe_averaged) {
            comm_count = DivCeil(m / EP , comm_m);
        } else {
            int32_t max_comm_count = 0;
            int32_t max_input_per_ep = 0;
            int32_t max_output_per_ep = 0;
            for (int32_t ep_idx = 0; ep_idx < EP; ep_idx++) {
                int32_t tmp_sum = 0;
                for(int32_t i = 0; i < local_expert_nums; i++) {
                    tmp_sum += global_tokens_per_expert_matrix[rank * expert_nums + ep_idx * local_expert_nums + i];
                }
                max_output_per_ep = max(max_output_per_ep, tmp_sum);
                tmp_sum = 0;
                for(int32_t i = 0; i < local_expert_nums; i++) {
                    tmp_sum += global_tokens_per_expert_matrix[ep_idx * expert_nums + rank * local_expert_nums + i];
                }
                max_input_per_ep = max(max_input_per_ep, tmp_sum);
                max_comm_count = max(max_comm_count, max(max_output_per_ep, max_input_per_ep));
            }
            comm_count = DivCeil(max_comm_count, comm_m);
        }


        int32_t out_num = 0;//发往 core_idx 卡的token数；
        int32_t before_rank_offset_src = 0;//发往core_idx卡的token的地址offset；
        int32_t cur_local_expert_id = 0;//当前正在发送的local expert id；
        int32_t cur_expert_len = 0;//当前发送的local expert 的token的长度;
        int32_t expert_remain_data_len;
        if (real_core_idx < rank_size) {
            if (is_moe_averaged) {
                before_rank_offset_src = (m / rank_size) * real_core_idx;
                out_num = (m / rank_size);
                cur_expert_len = m / rank_size / local_expert_nums;
            } else {
                for(int32_t i = 0; i < real_core_idx; i++){
                    for (int32_t j = 0; j < local_expert_nums; j++) {
                        before_rank_offset_src += global_tokens_per_expert_matrix[rank * expert_nums + j + i * local_expert_nums];
                    }
                }
                for(int32_t i = 0; i < local_expert_nums; i++) {
                    out_num += global_tokens_per_expert_matrix[rank * expert_nums + i + real_core_idx * local_expert_nums];
                }
                cur_expert_len = global_tokens_per_expert_matrix[rank * expert_nums + real_core_idx * local_expert_nums];
            }
        }
        expert_remain_data_len = cur_expert_len;
        


        if(dequant_granularity == QuantGranularity::PER_TOKEN){
            ScaleAllToAll();
        }


        int32_t cur_expert = real_core_idx * local_expert_nums;
        int32_t received_loop_number = 0;
        int32_t sum_out_this_core = 0; //已经发往 core_idx 卡的token数
        int32_t sum_in_expert = 0; //当前expert已经发送的token数

        for(int32_t comm_idx = 0; comm_idx < comm_count + MAX_BLOCK_COUNT; comm_idx++){
            uint64_t flag_idx = comm_idx % MAX_BLOCK_COUNT;
            int32_t received_rank_num = 0;
            if (is_moe_averaged){
                received_rank_num = rank_size;
            } else {
                for(int32_t i = 0; i < EP; i++){
                    int32_t in_loop_per_ep = 0;
                    for(int32_t j = 0; j < local_expert_nums; j++) {
                        in_loop_per_ep += global_tokens_per_expert_matrix[i * expert_nums + j + rank * local_expert_nums];
                    }
                    if (comm_idx * comm_m < in_loop_per_ep) {
                        received_rank_num += 1;
                    }
                }
            }
            received_loop_number += received_rank_num;

            if (comm_idx > 1) {
                WaitEvent(flag_idx);
            }
            SetAndWaitAivSync(flag_idx);


            if (real_core_idx < rank_size && comm_idx < comm_count) {
                if(real_core_idx == rank){
                    SetBuffFlagByAdd(ctrl_flags_UB, (__gm__ int32_t *)buff[rank] + flag_offset + 
                        FLAG_ZERO_IDX, FLAG_VALUE);
                }
                if(is_moe_averaged || comm_idx * comm_m < out_num){
                    int32_t data_len;
                    if ((comm_idx + 1) * comm_m >= out_num){
                        data_len = out_num - comm_idx * comm_m;
                    } else {
                        data_len = comm_m;
                    }

                    __gm__ T *src_address, *dst_address;
                    src_address = gm_out + 1LL * before_rank_offset_src * k_align + 1LL * comm_idx * comm_m * k_align;
                    CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + 
                        FLAG_ZERO_IDX, FLAG_VALUE * (comm_idx + 1));

                    //因为data_len的token可能跨expert，所以需要循环
                    int32_t remain_data_len = data_len;
                    while(cur_local_expert_id < local_expert_nums && remain_data_len > 0) {
                        int32_t move_data_len;
                        if (remain_data_len >= cur_expert_len - sum_in_expert) {
                            move_data_len = cur_expert_len - sum_in_expert;
                        } else {
                            move_data_len = remain_data_len;
                        }
                        
                        if (move_data_len > 0) {
                            move_data_len = 1LL * move_data_len * k_align;
                            //关键点：计算本次通信在目标卡共享内存内的地址
                            int32_t before_expert_offset = 0; //在目标卡的共享内存中这次通信expert的offset
                            int32_t before_rank_offset = 0; //在目标卡的共享内存中这次通信当前expert中当前rank的offset
                            for(int32_t i = 0; i < rank_size; i++) {
                                //第i张卡发往core_idx卡的token数。
                                int32_t out_this_rank = 0;
                                for (int32_t j = 0; j < local_expert_nums; j ++) {
                                    int32_t expert_token_num;
                                    if (is_moe_averaged) {
                                        expert_token_num = m / expert_nums;
                                    } else {
                                        expert_token_num = global_tokens_per_expert_matrix[i * expert_nums + real_core_idx * local_expert_nums + j];
                                    }
                                    out_this_rank += expert_token_num;
                                }

                                int32_t data_len_this_rank;
                                if ((comm_idx + 1) * comm_m >= out_this_rank) {
                                    data_len_this_rank = out_this_rank - comm_idx * comm_m;
                                } else {
                                    data_len_this_rank = comm_m;
                                }

                                //expert token数的前缀和
                                int32_t sum = 0;
                                for(int32_t j = 0; j < cur_local_expert_id; j++) {
                                    int32_t expert_id = real_core_idx * local_expert_nums + j;
                                    //本次通信，第i张卡发往expert_id的token数。
                                    //i卡发往expert的总的token数：
                                    int32_t expert_token_num;
                                    if (is_moe_averaged) {
                                        expert_token_num = m / expert_nums;
                                    } else {
                                        expert_token_num = global_tokens_per_expert_matrix[i * expert_nums + expert_id];
                                    }
                                    if (comm_idx * comm_m < sum + expert_token_num && comm_idx * comm_m + data_len_this_rank > sum) 
                                    {
                                        int32_t tmp_len = min(comm_idx * comm_m + data_len_this_rank, sum + expert_token_num) - 
                                                        max(comm_idx * comm_m, sum);
                                        before_expert_offset += tmp_len;
                                    }
                                    sum += expert_token_num;
                                }
                                if (i < rank) {
                                    int32_t expert_id = real_core_idx * local_expert_nums + cur_local_expert_id;
                                    int32_t expert_token_num;
                                    if (is_moe_averaged) {
                                        expert_token_num = m / expert_nums;
                                    } else {
                                        expert_token_num = global_tokens_per_expert_matrix[i * expert_nums + expert_id];
                                    }
                                    if ((comm_idx * comm_m < sum + expert_token_num) && (comm_idx * comm_m + data_len_this_rank > sum)) {
                                        int32_t tmp_len = min(comm_idx * comm_m + data_len_this_rank, sum + expert_token_num) - 
                                                        max(comm_idx * comm_m, sum);
                                        before_rank_offset += tmp_len;
                                    }
                                }
                            }

                            dst_address = buff[real_core_idx] + 1LL * flag_idx * gm_a_pingpong_size +
                                1LL * before_expert_offset * k_align + 1LL * before_rank_offset * k_align;
                            SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                            SetFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3
                            MoveResultFromSrcToDst(src_address, dst_address, move_data_len);
                            WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID0);  // MTE2等MTE3
                            WaitFlag<HardEvent::MTE3_MTE2>(EVENT_ID1);  // MTE2等MTE3
                        }

                        if (remain_data_len >= cur_expert_len - sum_in_expert) {
                            cur_local_expert_id ++;
                            remain_data_len -= (cur_expert_len - sum_in_expert);
                            if (is_moe_averaged) {
                                cur_expert_len = m / expert_nums;
                            } else if(cur_local_expert_id < local_expert_nums){
                                cur_expert_len = global_tokens_per_expert_matrix[rank * expert_nums + real_core_idx * local_expert_nums + cur_local_expert_id];
                            }
                            sum_in_expert = 0;
                        } else {
                            sum_in_expert += remain_data_len;
                            remain_data_len = 0;
                        }
                        src_address += move_data_len;
                    }

                    SetBuffFlagByAdd(ctrl_flags_UB, (__gm__ int32_t *)buff[real_core_idx] + flag_offset + 
                            FLAG_ONE_IDX, FLAG_VALUE);
                }
                if(real_core_idx == rank){ 
                    CheckBuffFlag(ctrl_flags_UB, (__gm__ int32_t *)buff[rank] + flag_offset + 
                        FLAG_ONE_IDX, FLAG_VALUE * received_loop_number);
                }
            }

            SetAndWaitAivSync(flag_idx); 
            SetAicSync(flag_idx);
        }

        if (dequant_granularity == QuantGranularity::PER_TOKEN) {
            serial_pertoken_dequant_runner.Run();
        }
        EndFlagsAndBias();
    }


public:
    using CocCommBase<T, MatType>::SetAicSync;
    using CocCommBase<T, MatType>::SetAndWaitAivSync;

    using CocCommBase<T, MatType>::SetBuffFlag;
    using CocCommBase<T, MatType>::SetBuffFlagByAdd;
    using CocCommBase<T, MatType>::CheckBuffFlag;
    using CocCommBase<T, MatType>::ResetIpcFlags;
    using CocCommBase<T, MatType>::CrossRankSyncV1;
    using CocCommBase<T, MatType>::CrossRankSyncV2;
    
    using CocCommBase<T, MatType>::buff;
    using CocCommBase<T, MatType>::gm_out;
    using CocCommBase<T, MatType>::ctrl_flags_UB;
    using CocCommBase<T, MatType>::output_UB_T;
    using CocCommBase<T, MatType>::batch_size;
    using CocCommBase<T, MatType>::m;
    using CocCommBase<T, MatType>::k;
    using CocCommBase<T, MatType>::n;
    using CocCommBase<T, MatType>::m0;
    using CocCommBase<T, MatType>::k0;
    using CocCommBase<T, MatType>::n0;
    using CocCommBase<T, MatType>::m_loop;
    using CocCommBase<T, MatType>::n_loop;
    using CocCommBase<T, MatType>::k_loop;
    using CocCommBase<T, MatType>::core_loop;
    using CocCommBase<T, MatType>::real_core_idx;
    using CocCommBase<T, MatType>::core_num;
    using CocCommBase<T, MatType>::rank;
    using CocCommBase<T, MatType>::rank_size;
    using CocCommBase<T, MatType>::tiling_key;
    using CocCommBase<T, MatType>::swizzl_direct;
    using CocCommBase<T, MatType>::swizzl_count;
    using CocCommBase<T, MatType>::trans_a;
    using CocCommBase<T, MatType>::trans_b;
    using CocCommBase<T, MatType>::is_int8;
    using CocCommBase<T, MatType>::p_value;
    using CocCommBase<T, MatType>::aiv_idx;
    using CocCommBase<T, MatType>::other_rank;
    using CocCommBase<T, MatType>::max_ub_single_dma_size;
    using CocCommBase<T, MatType>::max_ub_ping_pong_size;
    using CocCommBase<T, MatType>::dequant_granularity;
    using CocCommBase<T, MatType>::dequant_group_size;
    using CocCommBase<T, MatType>::quant_granularity;
    using CocCommBase<T, MatType>::quant_group_size;
    using CocCommBase<T, MatType>::workspace_info;
    using CocCommBase<T, MatType>::withSerialMode;


    using CocCommBase<T, MatType>::num_local_tokens_per_expert;
    using CocCommBase<T, MatType>::num_global_tokens_per_local_expert;
    using CocCommBase<T, MatType>::global_tokens_per_expert_matrix;

    using CocCommBase<T, MatType>::local_expert_nums;
    using CocCommBase<T, MatType>::TP;
    using CocCommBase<T, MatType>::EP;
    using CocCommBase<T, MatType>::is_moe;
    using CocCommBase<T, MatType>::is_moe_averaged;
    using CocCommBase<T, MatType>::is_alltoallvc;
    using CocCommBase<T, MatType>::is_deterministic;
    using CocCommBase<T, MatType>::maxOutputSize;
    using CocCommBase<T, MatType>::weight_nz;

    using CocCommBase<T, MatType>::comm_npu_split;
    using CocCommBase<T, MatType>::comm_data_split;
    using CocCommBase<T, MatType>::comm_direct;
    using CocCommBase<T, MatType>::len_per_loop;
    using CocCommBase<T, MatType>::core_count;
    using CocCommBase<T, MatType>::flag_offset;


    __gm__ int32_t *out_loop_per_ep;
    __gm__ int32_t *in_loop_per_ep;
    __gm__ int32_t *sum_num_local_tokens_per_expert;
    __gm__ int32_t *sum_num_global_tokens_per_local_expert;
    __gm__ int32_t *expert_comm_count_accum;

    __gm__ float32_t *gm_quant_scale;



    int32_t gm_a_pingpong_size;
    int32_t m_align;
    int32_t k_align;
    int32_t n_align;
    int32_t aligned_a;
    int32_t aligned_b;

    int32_t expert_nums;

    Preprocessor<T> preprocessor;
    AllGatherMatmulBiasAdder<T> add_bias_runner;
    SerialPerTokenDequantRunner<MatType> serial_pertoken_dequant_runner;
    
    bool need_dequant;
};



template <typename T>
inline __aicore__ void CocAllToAllVAllGatherAiv(COC_ARGS_FUN(T)){
    AllToAllvAllGather<false, T, T> alltoall_allgather_without_bias;
    AllToAllvAllGather<true, T, T> alltoall_allgather_with_bias;
    AllToAllvAllGather<false, uint8_t, T> alltoall_allgather_int8_without_bias;
    AllToAllvAllGather<true, uint8_t, T> alltoall_allgather_int8_with_bias;
    SetAtomicNone();
    SetMaskNormImpl();
    SetSyncBaseAddr((uint64_t)ffts_addr);
    SetVectorMask<T>((uint64_t)-1, (uint64_t)-1);
    
    auto para = reinterpret_cast<__gm__ Lcal::CoCKernelParam *>(para_gm);
    auto cocTilingData = &para->cocTilingData;
    int32_t tiling_key = cocTilingData->tilingKey;
    int32_t write_to_other_rank = cocTilingData->write2OtherRank;
    switch (tiling_key) {
        case 0b000000 : case 0b100000 : case 0b010000 : case 0b110000 :
        case 0b001000 : case 0b101000 : case 0b011000 : case 0b111000 :
            alltoall_allgather_without_bias.SetArgs(COC_ARGS_CALL());
            alltoall_allgather_without_bias.Run();
            break;
        case 0b000010 : case 0b100010 : case 0b010010 : case 0b110010 :
        case 0b001010 : case 0b101010 : case 0b011010 : case 0b111010 :
            alltoall_allgather_with_bias.SetArgs(COC_ARGS_CALL());
            alltoall_allgather_with_bias.Run();
            break;
        case 0b000100 : case 0b100100 : case 0b010100 : case 0b110100 :
        case 0b001100 : case 0b101100 : case 0b011100 : case 0b111100 :
            alltoall_allgather_int8_without_bias.SetArgs(COC_ARGS_CALL_INT8());
            alltoall_allgather_int8_without_bias.Run();
            break;
        case 0b000110 : case 0b100110 : case 0b010110 : case 0b110110 :
        case 0b001110 : case 0b101110 : case 0b011110 : case 0b111110 :
            alltoall_allgather_int8_with_bias.SetArgs(COC_ARGS_CALL_INT8());
            alltoall_allgather_int8_with_bias.Run();
            break;
        default :
            break;
    }
    PipeBarrier<PIPE_ALL>();
}

#endif
