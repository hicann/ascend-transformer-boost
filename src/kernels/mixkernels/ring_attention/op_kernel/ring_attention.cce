/*
* Copyright (c) 2024 Huawei Technologies Co., Ltd.
* This file is a part of the CANN Open Software.
* Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
* Please refer to the License for details. You may not use this file except in compliance with the License.
* THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
* INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
* See LICENSE in the root of the software repository for the full text of the License.
*/

#include "kernels/utils/kernel/common.h"
#include "kernels/utils/kernel/common_func.h"
#include "kernels/utils/kernel/simd.h"
#include "kernels/utils/kernel/iterator.h"
#include "kernels/utils/kernel/mma.h"
#include "kernels/utils/kernel/utils.h"
#include "kernel_operator.h"


#ifdef __CCE_KT_TEST__
#define __aicore__
#else
#define __aicore__ [aicore]
#endif

// FFTS Flag
constexpr int32_t QK_READY = 1;
constexpr int32_t SOFTMAX_READY = 2;
constexpr int32_t UPDATE_READY = 3;
constexpr int32_t BIT_SHIFT = 8;
constexpr int32_t SOFTMAX_MAX_LENGTH = 256;
constexpr int32_t NO_STACK_S_BLOCK_LIMIT = 4;

#ifdef __DAV_C220_CUBE__
constexpr int32_t L0AB_HALF_BUF_SIZE = 16384;  // 128 * 128
constexpr int32_t BLOCK_SIZE = 16;
constexpr int32_t CUBE_MATRIX_SIZE = 256;         // 16 * 16
constexpr int32_t L0AB_UINT8_BLOCK_SIZE = 32768;  // 128 * 128 * 2B
constexpr int32_t TMP_SIZE = 32768 * 4;               // 128 * 256 * 2
constexpr int32_t TMP_SIZET = 16384;               // 128 * 256 * 2
constexpr int32_t BLOCK_QK = 128;
constexpr int32_t LOCAL_SIZE = 6;

extern "C" __global__ __aicore__ void ring_attention(
    __gm__ uint8_t *__restrict__ sync,
    __gm__ uint8_t *__restrict__ q_gm,
    __gm__ uint8_t *__restrict__ k_gm,
    __gm__ uint8_t *__restrict__ v_gm,
    __gm__ uint8_t *__restrict__ layerID_gm,
    __gm__ uint8_t *__restrict__ mask_gm,
    __gm__ uint8_t *__restrict__ alibi_coeff_gm,
    __gm__ uint8_t *__restrict__ deq_qk_gm,
    __gm__ uint8_t *__restrict__ off_qk_gm,
    __gm__ uint8_t *__restrict__ deq_pv_gm,
    __gm__ uint8_t *__restrict__ off_pv_gm,
    __gm__ uint8_t *__restrict__ quant_p_gm,
    __gm__ uint8_t *__restrict__ logN_gm,
    __gm__ uint8_t *__restrict__ o_prev,
    __gm__ uint8_t *__restrict__ lse_prev,
    __gm__ uint8_t *__restrict__ o_gm,
    __gm__ uint8_t *__restrict__ lse_gm,
    __gm__ uint8_t *__restrict__ s_gm,
    __gm__ uint8_t *__restrict__ p_gm,
    __gm__ uint8_t *__restrict__ o_tmp_gm,
    __gm__ uint8_t *__restrict__ upo_tmp_gm,
    __gm__ uint8_t *__restrict__ tiling_para_gm)
{
    SetFftsBaseAddr((unsigned long)sync);
    SetPadding<uint64_t>(0);
    SetAtomicnone();
    SetNdpara(1, 0, 0);
    SetMasknorm();

    const uint32_t l1q_buf_addr_offset = 0;
    const uint32_t l1k_buf_addr_offset = 2 * L0AB_UINT8_BLOCK_SIZE;
    const uint32_t l1p_buf_addr_offset = 4 * L0AB_UINT8_BLOCK_SIZE;
    const uint32_t l1v_buf_addr_offset = 6 * L0AB_UINT8_BLOCK_SIZE;

    AsdopsBuffer<ArchType::ASCEND_V220> buf;

    AscendC::LocalTensor<half> l1q_buf_addr_tensor = buf.GetBuffer<BufferType::ASCEND_CB, half>(l1q_buf_addr_offset);
    AscendC::LocalTensor<half> l1k_buf_addr_tensor = buf.GetBuffer<BufferType::ASCEND_CB, half>(l1k_buf_addr_offset);
    AscendC::LocalTensor<half> l1p_buf_addr_tensor = buf.GetBuffer<BufferType::ASCEND_CB, half>(l1p_buf_addr_offset);
    AscendC::LocalTensor<half> l1v_buf_addr_tensor = buf.GetBuffer<BufferType::ASCEND_CB, half>(l1v_buf_addr_offset);

    AscendC::LocalTensor<half> l0a_buf_tensor = buf.GetBuffer<BufferType::ASCEND_L0A, half>(0);
    AscendC::LocalTensor<half> l0b_buf_tensor = buf.GetBuffer<BufferType::ASCEND_L0B, half>(0);
    AscendC::LocalTensor<float> l0c_buf_tensor = buf.GetBuffer<BufferType::ASCEND_L0C, float>(0);

    uint32_t batch_size = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm));
    uint32_t max_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 1));
    uint32_t q_heads = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 2));
    uint32_t embd = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 3));
    uint32_t embdv = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 23));
    uint32_t kv_heads = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 4));
    uint32_t is_triu_mask = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 8));
    uint32_t total_q_blk_num = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 9));
    uint32_t tiling_head_size = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 14));
    uint32_t tiling_para_size = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 15));
    uint32_t max_kv_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 18));

    uint32_t data_shape_type = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 24));

    uint32_t group_num = q_heads / kv_heads;
    uint64_t stride_qo = q_heads * embd;
    uint64_t stride_k = kv_heads * embd;
    uint64_t stride_v = kv_heads * embdv;
    if (data_shape_type == 1)
    {
        stride_qo = embd;
        stride_k = embd;
        stride_v = embdv;
    }

    uint64_t batch_stride_k = batch_size * max_kv_seqlen * kv_heads * embd * 2;
    uint64_t batch_stride_v = batch_size * max_kv_seqlen * kv_heads * embdv * 2;
    if (layerID_gm != nullptr) {
        uint32_t layer_id = *(__gm__ uint32_t *)layerID_gm;
        k_gm = k_gm + layer_id * batch_stride_k;
        v_gm = v_gm + layer_id * batch_stride_v;
    }

    AscendC::GlobalTensor<half> q_gm_tensor;
    AscendC::GlobalTensor<half> k_gm_tensor;
    AscendC::GlobalTensor<half> v_gm_tensor;
    AscendC::GlobalTensor<half> s_gm_tensor;
    AscendC::GlobalTensor<half> p_gm_tensor;
    AscendC::GlobalTensor<float> o_tmp_gm_tensor;
    AscendC::GlobalTensor<float> upo_gm_tensor;

    q_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(q_gm));
    k_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(k_gm));
    v_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(v_gm));
    s_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(s_gm));
    p_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(p_gm));
    o_tmp_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(o_tmp_gm));
    upo_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(upo_tmp_gm));

    SET_FLAG(MTE1, MTE2, EVENT_ID0);
    SET_FLAG(MTE1, MTE2, EVENT_ID1);
    SET_FLAG(MTE1, MTE2, EVENT_ID2);
    SET_FLAG(MTE1, MTE2, EVENT_ID3);
    SET_FLAG(MTE1, MTE2, EVENT_ID5);
    SET_FLAG(MTE1, MTE2, EVENT_ID6);
    SET_FLAG(M, MTE1, EVENT_ID0);
    SET_FLAG(M, MTE1, EVENT_ID1);
    SET_FLAG(M, MTE1, EVENT_ID2);
    SET_FLAG(M, MTE1, EVENT_ID3);
    SET_FLAG(FIX, M, EVENT_ID0);
    SET_FLAG(FIX, M, EVENT_ID1);

    uint64_t cur_batch = 0;
    uint32_t pre_total_q_blk_num = 0;
    uint32_t offset_tiling = tiling_head_size + tiling_para_size * cur_batch;
    uint32_t cur_total_q_blk_num = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 13 + offset_tiling));
    uint32_t process_num = total_q_blk_num * q_heads;
    uint32_t next_process = 0;
    for (uint32_t process = block_idx; process < process_num; process = next_process) {
        while (process >= cur_total_q_blk_num * q_heads) {
            cur_batch++;
            pre_total_q_blk_num = cur_total_q_blk_num;
            offset_tiling += tiling_para_size;
            cur_total_q_blk_num = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 13 + offset_tiling));
        }
        next_process = process + block_num;
        if (is_triu_mask) {
            uint32_t curr_iter = process / block_num;
            next_process = curr_iter % 2 == 1 ? (curr_iter + 1) * block_num + block_idx : (curr_iter + 2) * block_num - 1 - block_idx;
        }

        // get tiling args
        uint32_t q_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + offset_tiling));
        uint32_t kv_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 1 + offset_tiling));
        if (q_seqlen == 0 || kv_seqlen == 0) {
            continue;
        }
        uint32_t pp_m_scalar = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 2 + offset_tiling));
        uint32_t pp_n_scalar = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 3 + offset_tiling));
        uint32_t addr_q_high32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 4 + offset_tiling));
        uint32_t addr_q_loww32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 5 + offset_tiling));
        uint64_t addr_q_scalar = (uint64_t)(((uint64_t)addr_q_high32) << 32 | addr_q_loww32);
        uint32_t addr_k_high32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 6 + offset_tiling));
        uint32_t addr_k_loww32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 7 + offset_tiling));
        uint64_t addr_k_scalar = (uint64_t)(((uint64_t)addr_k_high32) << 32 | addr_k_loww32);
        uint32_t addr_v_high32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 8 + offset_tiling));
        uint32_t addr_v_loww32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 9 + offset_tiling));
        uint64_t addr_v_scalar = (uint64_t)(((uint64_t)addr_v_high32) << 32 | addr_v_loww32);

        uint32_t process_idx = process - pre_total_q_blk_num * q_heads;
        uint32_t m_idx = process_idx / q_heads;
        uint64_t head_idx = process_idx % q_heads;

        // for prefix triu_mask
        uint32_t prefixLen = kv_seqlen - q_seqlen;
        uint32_t prefixBlockNum = (prefixLen + pp_m_scalar - 1) / pp_m_scalar;

        uint32_t m_loop = (q_seqlen + pp_m_scalar - 1) / pp_m_scalar;
        uint32_t n_loop = (kv_seqlen + pp_n_scalar - 1) / pp_n_scalar;

        uint32_t qk_m = (m_idx == (m_loop - 1)) ? (q_seqlen - m_idx * pp_m_scalar) : pp_m_scalar;
        uint32_t qk_round_m = (qk_m + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;

        /**************** pre_load *****************/
        uint32_t qk_n = n_loop == 1 ? kv_seqlen : pp_n_scalar;
        uint32_t qk_round_n = (qk_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;

        uint32_t pingpong_flag = 0;
        uint32_t offset = pingpong_flag * L0AB_HALF_BUF_SIZE;

        uint64_t q_offset = addr_q_scalar + head_idx * embd + m_idx * pp_m_scalar * stride_qo;
        uint64_t k_offset = addr_k_scalar + (head_idx / group_num) * embd;

        if (data_shape_type == 1)
        {
            q_offset = addr_q_scalar + head_idx * embd * max_seqlen + m_idx * stride_qo * pp_m_scalar;
            k_offset = addr_k_scalar + (head_idx / group_num) * embd * max_kv_seqlen;
        }


        uint32_t sv_n = n_loop == 1 ? kv_seqlen : pp_n_scalar;
        uint32_t sv_round_n = (sv_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
        uint64_t v_offset = addr_v_scalar + (head_idx / group_num) * embdv;
        if(data_shape_type == 1){
            v_offset = addr_v_scalar + (head_idx / group_num) * embdv * max_kv_seqlen;
        }

        uint32_t n_end = n_loop;
        if (is_triu_mask) {
            n_end = m_idx + prefixBlockNum + 1;
        }
        uint32_t s_block_stack = n_end > NO_STACK_S_BLOCK_LIMIT ? 2 : 1; // Currently not splitting K
        uint32_t launch_delay = s_block_stack * 2;
        uint32_t vect_mod = 2 * launch_delay;
        uint32_t loopQK = (embd + BLOCK_QK - 1) / BLOCK_QK;
        uint32_t loopV = (embdv + BLOCK_QK - 1) / BLOCK_QK;
        uint32_t qk_k = BLOCK_QK;
        uint32_t qk_round_k = BLOCK_QK;
        for (uint32_t n_idx = 0; n_idx < n_end + launch_delay; n_idx += s_block_stack) {
            if (n_idx < n_end) {
                for (uint32_t split_idx = 0; split_idx < s_block_stack && n_idx + split_idx < n_end; split_idx++) {
                    pingpong_flag = (n_idx + split_idx) % 2;
                    offset = pingpong_flag * L0AB_HALF_BUF_SIZE;
                    if (n_idx + split_idx == (n_loop - 1)) {
                        qk_n = (kv_seqlen - (n_idx + split_idx) * pp_n_scalar);
                        qk_round_n = (qk_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                    }
                    bool last_split = split_idx == s_block_stack - 1 || n_idx + split_idx == n_end - 1;
                    for(uint32_t k_idx = 0; k_idx < loopQK; k_idx++){
                        uint32_t initc = (k_idx == 0) ? 1 : 0;
                        qk_k = (k_idx == (loopQK - 1))? embd - k_idx * BLOCK_QK : BLOCK_QK;
                        qk_round_k = (qk_k + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                        uint64_t q_offsetk = q_offset + BLOCK_QK * k_idx;
                        uint64_t k_offsetk = k_offset + BLOCK_QK * k_idx;
                        WAIT_FLAG(MTE1, MTE2, pingpong_flag + 5);
                        if (qk_m == 1) {
                            gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::ND>(
                                l1q_buf_addr_tensor[offset],
                                q_gm_tensor[q_offsetk],
                                1,
                                0,
                                0,
                                qk_round_k,               // lenBurst
                                0,
                                0
                            );
                        } else {
                            gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::NZ>(
                                l1q_buf_addr_tensor[offset],
                                q_gm_tensor[q_offsetk],
                                qk_m,        // nValue
                                qk_round_m,  // dstNzC0Stride
                                0,            // dstNzMatrixStride, unused
                                qk_k,         // dValue
                                0,            // dstNzMatrixStride, unused
                                stride_qo   // srcDValue
                            );
                        }
                        SET_FLAG(MTE2, MTE1, pingpong_flag + 4);
                        WAIT_FLAG(MTE2, MTE1, pingpong_flag + 4);
                        WAIT_FLAG(M, MTE1, pingpong_flag);
                        if (qk_m == 1) {
                            l1_to_l0_a<ArchType::ASCEND_V220, half, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                                l0a_buf_tensor[offset],
                                l1q_buf_addr_tensor[offset],
                                0,
                                (qk_round_k + CUBE_MATRIX_SIZE - 1) / CUBE_MATRIX_SIZE,  // repeat
                                0,
                                1,                                                    // srcStride
                                0,
                                0                                                    // dstStride
                            );
                        } else {
                            for (uint32_t l0a_load_idx = 0; l0a_load_idx < qk_round_m / BLOCK_SIZE; ++l0a_load_idx) {
                                l1_to_l0_a<ArchType::ASCEND_V220, half, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                                    l0a_buf_tensor[offset + l0a_load_idx * qk_round_k * BLOCK_SIZE],
                                    l1q_buf_addr_tensor[offset + l0a_load_idx * CUBE_MATRIX_SIZE],
                                    0,
                                    qk_round_k / BLOCK_SIZE,     // repeat
                                    0,
                                    qk_round_m / BLOCK_SIZE,  // srcStride
                                    0,
                                    0                        // dstStride
                                );
                            }
                        }
                        SET_FLAG(MTE1, MTE2, pingpong_flag + 5);
                        SET_FLAG(MTE1, M, pingpong_flag);

                        WAIT_FLAG(MTE1, MTE2, pingpong_flag);
                        gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::NZ>(
                            l1k_buf_addr_tensor[offset],
                            k_gm_tensor[k_offsetk],
                            qk_n,        // nValue
                            qk_round_n,  // dstNzC0Stride
                            0,            // dstNzMatrixStride, unused
                            qk_k,         // dValue
                            0,            // dstNzMatrixStride, unused
                            stride_k   // srcDValue
                        );
                        SET_FLAG(MTE2, MTE1, pingpong_flag);
                        WAIT_FLAG(M, MTE1, pingpong_flag + 2);
                        WAIT_FLAG(MTE2, MTE1, pingpong_flag);
                        l1_to_l0_b<ArchType::ASCEND_V220, half, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                            l0b_buf_tensor[offset],
                            l1k_buf_addr_tensor[offset],
                            0,
                            qk_round_k * qk_round_n / CUBE_MATRIX_SIZE,  // repeat
                            0,
                            1,                                        // srcStride
                            0,
                            0                                        // dstStride
                        );
                        SET_FLAG(MTE1, MTE2, pingpong_flag);
                        SET_FLAG(MTE1, M, pingpong_flag + 2);
                        WAIT_FLAG(MTE1, M, pingpong_flag);
                        WAIT_FLAG(MTE1, M, pingpong_flag + 2);
                        if (split_idx == 0 && initc) {
                            WAIT_FLAG(FIX, M, EVENT_ID0);
                            WAIT_FLAG(FIX, M, EVENT_ID1);
                        }
                        mmad<ArchType::ASCEND_V220, half, half, float, false>(
                            l0c_buf_tensor[split_idx * qk_round_m * pp_n_scalar],
                            l0a_buf_tensor[offset],
                            l0b_buf_tensor[offset],
                            qk_m,  // m
                            qk_n,  // n
                            qk_k,   // k
                            initc      // cmatrixInitVal
                        );
                        PIPE_BARRIER(M);
                        SET_FLAG(M, MTE1, pingpong_flag);
                        SET_FLAG(M, MTE1, pingpong_flag + 2);
                    }
                    k_offset += pp_n_scalar * stride_k;
                }
                SET_FLAG(M, FIX, EVENT_ID0);
                WAIT_FLAG(M, FIX, EVENT_ID0);
                uint32_t sv_n_triu = n_end * pp_n_scalar;
                if (n_idx + s_block_stack > n_end - 1) {
                    sv_n = sv_n_triu > kv_seqlen ? kv_seqlen - n_idx * pp_n_scalar : sv_n_triu - n_idx * pp_n_scalar;
                } else {
                    sv_n = pp_n_scalar * s_block_stack;
                }
                sv_round_n = (sv_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                l0c_to_gm<ArchType::ASCEND_V220, DataFormat::ND, half, float>(
                    s_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod],
                    l0c_buf_tensor,
                    qk_m,        // MSize
                    sv_round_n,  // NSize
                    qk_round_m,  // srcStride
                    sv_round_n  // dstStride_dst_D
                );
                SET_FLAG(FIX, M, EVENT_ID0);
                SET_FLAG(FIX, M, EVENT_ID1);
                FftsCrossCoreSync<PIPE_FIX, 2>(QK_READY);
            }
            if (n_idx >= launch_delay) {
                uint32_t l0c_pingpong_flag = n_idx % 2;
                uint32_t l0c_offset = l0c_pingpong_flag * L0AB_HALF_BUF_SIZE;
                uint32_t sv_n_triu = n_end * pp_n_scalar;
                if (n_idx + s_block_stack > n_end + launch_delay - 1) {
                    sv_n = sv_n_triu > kv_seqlen ? kv_seqlen - (n_idx - launch_delay) * pp_n_scalar : sv_n_triu - (n_idx - launch_delay) * pp_n_scalar;
                } else {
                    sv_n = pp_n_scalar * s_block_stack;
                }
                sv_round_n = (sv_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                for(uint32_t k_idx = 0; k_idx < loopV; k_idx++){
                    qk_k = (k_idx == (loopV - 1))? embdv - k_idx * BLOCK_QK : BLOCK_QK;
                    qk_round_k = (qk_k + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                    uint64_t v_offsetk = v_offset + BLOCK_QK * k_idx;
                    WAIT_FLAG(MTE1, MTE2, EVENT_ID2);
                    gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::NZ>(
                        l1v_buf_addr_tensor,
                        v_gm_tensor[v_offsetk],
                        sv_n,        // nValue
                        sv_round_n,  // dstNzC0Stride
                        0,            // dstNzMatrixStride, unused
                        qk_k,         // dValue
                        0,            // dstNzMatrixStride, unused
                        stride_v   // srcDValue
                    );
                    SET_FLAG(MTE2, MTE1, EVENT_ID2);
                    WAIT_FLAG(MTE2, MTE1, EVENT_ID2);
                    WAIT_FLAG(M, MTE1, EVENT_ID2);
                    WAIT_FLAG(M, MTE1, EVENT_ID3);
                    for (uint32_t l0b_load_idx = 0; l0b_load_idx < sv_round_n / BLOCK_SIZE; ++l0b_load_idx) {
                        l1_to_l0_b<ArchType::ASCEND_V220, half, true, DataFormat::VECTOR, DataFormat::VECTOR>(
                            l0b_buf_tensor[l0b_load_idx * qk_round_k * BLOCK_SIZE],
                            l1v_buf_addr_tensor[l0b_load_idx * CUBE_MATRIX_SIZE],
                            0,
                            qk_round_k / BLOCK_SIZE,     // repeat
                            0,
                            sv_round_n / BLOCK_SIZE,  // srcStride
                            0,
                            0                        // dstStride
                        );
                    }
                    SET_FLAG(MTE1, M, EVENT_ID6);
                    SET_FLAG(MTE1, MTE2, EVENT_ID2);
                    if(k_idx == 0){
                        WaitFlagDev(SOFTMAX_READY);
                        WAIT_FLAG(MTE1, MTE2, EVENT_ID3);
                        if (qk_m == 1) {
                            gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::ND>(
                                l1p_buf_addr_tensor,
                                p_gm_tensor[(uint64_t)block_idx * TMP_SIZE + (n_idx - launch_delay) % vect_mod * TMP_SIZE / vect_mod],
                                1,
                                0,
                                0,
                                sv_round_n,               // lenBurst
                                0,
                                0
                            );
                        } else {
                            gm_to_l1<ArchType::ASCEND_V220, half, DataFormat::ND, DataFormat::NZ>(
                                l1p_buf_addr_tensor,
                                p_gm_tensor[(uint64_t)block_idx * TMP_SIZE + (n_idx - launch_delay) % vect_mod * TMP_SIZE / vect_mod],
                                qk_m,        // nValue
                                qk_round_m,  // dstNzC0Stride
                                0,            // dstNzMatrixStride, unused
                                sv_n,        // dValue
                                0,            // dstNzMatrixStride, unused
                                sv_round_n  // srcDValue
                            );
                        }
                        SET_FLAG(MTE2, MTE1, EVENT_ID3);
                        WAIT_FLAG(MTE2, MTE1, EVENT_ID3);
                        WAIT_FLAG(M, MTE1, EVENT_ID0);
                        WAIT_FLAG(M, MTE1, EVENT_ID1);
                        if (qk_m == 1) {
                            l1_to_l0_a<ArchType::ASCEND_V220, half, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                                l0a_buf_tensor,
                                l1p_buf_addr_tensor,
                                0,
                                (sv_round_n + CUBE_MATRIX_SIZE - 1) / CUBE_MATRIX_SIZE,  // repeat
                                0,
                                1,                                                       // srcStride
                                0,
                                0                                                       // dstStride
                            );
                        } else {
                            for (uint32_t l0a_load_idx = 0; l0a_load_idx < qk_round_m / BLOCK_SIZE; ++l0a_load_idx) {
                                l1_to_l0_a<ArchType::ASCEND_V220, half, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                                    l0a_buf_tensor[l0a_load_idx * sv_round_n * BLOCK_SIZE],
                                    l1p_buf_addr_tensor[l0a_load_idx * CUBE_MATRIX_SIZE],
                                    0,
                                    sv_round_n / BLOCK_SIZE,  // repeat
                                    0,
                                    qk_round_m / BLOCK_SIZE,  // srcStride
                                    0,
                                    0                        // dstStride
                                );
                            }
                        }
                        SET_FLAG(MTE1, MTE2, EVENT_ID3);
                    }
                    SET_FLAG(MTE1, M, EVENT_ID5);
                    WAIT_FLAG(MTE1, M, EVENT_ID5);
                    WAIT_FLAG(MTE1, M, EVENT_ID6);
                    WAIT_FLAG(FIX, M, l0c_pingpong_flag);
                    mmad<ArchType::ASCEND_V220, half, half, float, false>(
                        l0c_buf_tensor[l0c_offset],
                        l0a_buf_tensor,
                        l0b_buf_tensor,
                        qk_m,  // m
                        qk_k,   // n
                        sv_n,  // k
                        1      // cmatrixInitVal
                    );
                    PIPE_BARRIER(M);
                    if(k_idx == loopV - 1){
                        SET_FLAG(M, MTE1, EVENT_ID0);
                        SET_FLAG(M, MTE1, EVENT_ID1);
                    }
                    SET_FLAG(M, MTE1, EVENT_ID2);
                    SET_FLAG(M, MTE1, EVENT_ID3);
                    SET_FLAG(M, FIX, l0c_pingpong_flag);
                    WAIT_FLAG(M, FIX, l0c_pingpong_flag);
                    // copy O to gm
                    l0c_to_gm<ArchType::ASCEND_V220, DataFormat::ND, float, float>(
                        o_tmp_gm_tensor[(uint64_t)block_idx * TMP_SIZE * LOCAL_SIZE + k_idx * TMP_SIZET  + (n_idx - launch_delay) % vect_mod * TMP_SIZE / vect_mod * loopV],
                        l0c_buf_tensor[l0c_offset],
                        qk_m,        // MSize
                        qk_round_k,     // NSize
                        qk_round_m,  // srcStride
                        qk_round_k     // dstStride_dst_D
                    );
                    SET_FLAG(FIX, M, l0c_pingpong_flag);
                }
                FftsCrossCoreSync<PIPE_FIX, 2>(UPDATE_READY);
                v_offset += sv_n * stride_v;
            }
        }
    }
    WAIT_FLAG(MTE1, MTE2, EVENT_ID0);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID1);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID2);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID3);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID5);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID6);
    WAIT_FLAG(M, MTE1, EVENT_ID0);
    WAIT_FLAG(M, MTE1, EVENT_ID1);
    WAIT_FLAG(M, MTE1, EVENT_ID2);
    WAIT_FLAG(M, MTE1, EVENT_ID3);
    WAIT_FLAG(FIX, M, EVENT_ID0);
    WAIT_FLAG(FIX, M, EVENT_ID1);

    PIPE_BARRIER(ALL);
}
#endif

#ifdef __DAV_C220_VEC__
constexpr int32_t BLOCK_SIZE = 16;
constexpr int32_t FLOAT_BLOCK_SIZE = 8;
constexpr int32_t LONG_SEQ_MASK_LEN = 128;
constexpr int32_t VECTOR_SIZE = 128;
constexpr int32_t COMPRESS_MASK_SIZE = 8192;
constexpr int32_t FLOAT_VECTOR_SIZE = 64;
constexpr int32_t UB_UINT8_BLOCK_SIZE = 16384;  // 64 * 128 * 2B
constexpr int32_t UB_HALF_BUF_SIZE = 8192;      // 64 * 128
constexpr int32_t UB_UINT8_LINE_SIZE = 512;     // 128 * 4B
constexpr int32_t UB_FLOAT_LINE_SIZE = 64;     // 128
constexpr int32_t UB_HALF_LINE_SIZE = 128;      // UB_FLOAT_LINE_SIZE * 2
constexpr int32_t TMP_SIZE = 32768 * 4;             // 128 * 256
constexpr int32_t TMP_SIZET = 16384;
constexpr int32_t TOTAL_UB_SIZE = 192 * 1024;
constexpr int32_t BLOCK_QK = 128;
constexpr int32_t ROWMAX_TEMP_BUF_OFFSET = 1024;
constexpr int32_t LOCAL_SIZE = 6;

__aicore__ __attribute__((always_inline)) inline void __set_mask(int32_t len)
{
    uint64_t mask = 0;
    uint64_t one = 1;
    uint64_t temp = len % FLOAT_VECTOR_SIZE;
    for (int64_t i = 0; i < temp; i++) {
        mask |= one << i;
    }

    if (len == VECTOR_SIZE || len == 0) {
        SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
    } else if (len >= FLOAT_VECTOR_SIZE) {
        SetVectorMask<int8_t>(mask, (uint64_t)-1);
    } else {
        SetVectorMask<int8_t>(0x0, mask);
    }
}

__aicore__ __attribute__((always_inline)) inline void __set_vcg_mask(int32_t len)
{
    if (len > 16 || len < 1) {
        SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
        return;
    }
    uint64_t subMask = ((uint64_t) 1 << len) - 1;
    uint64_t maskValue = (subMask << 48) + (subMask << 32) + (subMask << 16) + subMask;
    SetVectorMask<int8_t>(maskValue, maskValue);
}

extern "C" __global__ __aicore__ void ring_attention(
    __gm__ uint8_t *__restrict__ sync,
    __gm__ uint8_t *__restrict__ q_gm,
    __gm__ uint8_t *__restrict__ k_gm,
    __gm__ uint8_t *__restrict__ v_gm,
    __gm__ uint8_t *__restrict__ layerID_gm,
    __gm__ uint8_t *__restrict__ mask_gm,
    __gm__ uint8_t *__restrict__ alibi_coeff_gm,
    __gm__ uint8_t *__restrict__ deq_qk_gm,
    __gm__ uint8_t *__restrict__ off_qk_gm,
    __gm__ uint8_t *__restrict__ deq_pv_gm,
    __gm__ uint8_t *__restrict__ off_pv_gm,
    __gm__ uint8_t *__restrict__ quant_p_gm,
    __gm__ uint8_t *__restrict__ logN_gm,
    __gm__ uint8_t *__restrict__ o_prev,
    __gm__ uint8_t *__restrict__ lse_prev,
    __gm__ uint8_t *__restrict__ o_gm,
    __gm__ uint8_t *__restrict__ lse_gm,
    __gm__ uint8_t *__restrict__ s_gm,
    __gm__ uint8_t *__restrict__ p_gm,
    __gm__ uint8_t *__restrict__ o_tmp_gm,
    __gm__ uint8_t *__restrict__ upo_tmp_gm,
    __gm__ uint8_t *__restrict__ tiling_para_gm)
{
    SetFftsBaseAddr((unsigned long)sync);
    int32_t sub_block_idx = GetSubBlockidx();
    SetAtomicnone();
    SetMasknorm();
    SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);

    const uint32_t ls_ubuf_offset = 0;
    const uint32_t lp_ubuf_offset = 0;
    const uint32_t ls32_ubuf_offset = 2 * UB_UINT8_BLOCK_SIZE;
    const uint32_t mask_ubuf_offset = 4 * UB_UINT8_BLOCK_SIZE;
    const uint32_t lo_ubuf_offset = 6 * UB_UINT8_BLOCK_SIZE;
    const uint32_t lm_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE;
    const uint32_t hm_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 1 * UB_UINT8_LINE_SIZE;
    const uint32_t gm_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 2 * UB_UINT8_LINE_SIZE;
    const uint32_t dm_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 4 * UB_UINT8_LINE_SIZE;
    const uint32_t ll_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 8 * UB_UINT8_LINE_SIZE;
    const uint32_t gl_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 16 * UB_UINT8_LINE_SIZE;
    const uint32_t lse_prev_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 17 * UB_UINT8_LINE_SIZE;
    const uint32_t lse_cur_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 18 * UB_UINT8_LINE_SIZE;
    const uint32_t lse_conv_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 19 * UB_UINT8_LINE_SIZE;
    const uint32_t lse_cur_update_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 20 * UB_UINT8_LINE_SIZE;
    const uint32_t lse_prev_update_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 21 * UB_UINT8_LINE_SIZE;
    const uint32_t tv_ubuf_offset = 8 * UB_UINT8_BLOCK_SIZE + 24 * UB_UINT8_LINE_SIZE;
    const uint32_t go_ubuf_offset = 9 * UB_UINT8_BLOCK_SIZE;
    const uint32_t o_prev_ubuf_offset = 11 * UB_UINT8_BLOCK_SIZE;

    AsdopsBuffer<ArchType::ASCEND_V220> buf;

    AscendC::LocalTensor<half> ls_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(ls_ubuf_offset);
    AscendC::LocalTensor<half> lp_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lp_ubuf_offset);
    AscendC::LocalTensor<float> ls32_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(ls32_ubuf_offset);  // ls32_ubuf_offset只作为临时用、复用
//    AscendC::LocalTensor<half> lsein_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lsein_ubuf_offset); // lse输入ub部分空间
    AscendC::LocalTensor<half> mask_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(mask_ubuf_offset);
    AscendC::LocalTensor<half> mask_value_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(11 * UB_UINT8_BLOCK_SIZE);
    AscendC::LocalTensor<uint8_t> mask_u8_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, uint8_t>(11 * UB_UINT8_BLOCK_SIZE);
    AscendC::LocalTensor<float> lo_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lo_ubuf_offset);
    AscendC::LocalTensor<half> lm_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lm_ubuf_offset);
    AscendC::LocalTensor<half> hm_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(hm_ubuf_offset);
    AscendC::LocalTensor<half> gm_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(gm_ubuf_offset);
    AscendC::LocalTensor<half> dm_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(dm_ubuf_offset);
    AscendC::LocalTensor<float> ll_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(ll_ubuf_offset);
    AscendC::LocalTensor<float> gl_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(gl_ubuf_offset);
    AscendC::LocalTensor<float> tv_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(tv_ubuf_offset);
    AscendC::LocalTensor<half> tv16_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(tv_ubuf_offset);
    AscendC::LocalTensor<uint8_t> tv_u8_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, uint8_t>(tv_ubuf_offset);
    AscendC::LocalTensor<float> go_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(go_ubuf_offset); // new_o

    AscendC::LocalTensor<half> lse_prev_ub_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lse_prev_ubuf_offset); // lse_prev_ub_tensor offset设置？？？
    AscendC::LocalTensor<float> lse32_prev_ub_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lse_prev_ubuf_offset); // lse_prev_ub_tensor offset设置？？？
    AscendC::LocalTensor<half> lse_conv_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lse_conv_ubuf_offset); // 用于中间new_lse变量参与计算与存放
    AscendC::LocalTensor<float> lse32_conv_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lse_conv_ubuf_offset); // 用于中间new_lse变量参与计算与存放
    AscendC::LocalTensor<half> lse_cur_update_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lse_cur_update_ubuf_offset); // 用于中间new_lse变量参与计算与存放
    AscendC::LocalTensor<float> lse32_cur_update_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lse_cur_update_ubuf_offset); //
    AscendC::LocalTensor<half> lse_prev_update_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lse_prev_update_ubuf_offset); // 用于中间new_lse变量参与计算与存放
    AscendC::LocalTensor<float> lse32_prev_update_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lse_prev_update_ubuf_offset); //
    AscendC::LocalTensor<half> lse_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(lse_cur_ubuf_offset);
    AscendC::LocalTensor<float> lse32_ubuf_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lse_cur_ubuf_offset);

    AscendC::LocalTensor<half> o_prev_ub_tensor = buf.GetBuffer<BufferType::ASCEND_UB, half>(o_prev_ubuf_offset); // o_prev搬入ub的变量准备  lo_ubuf_offset
    AscendC::LocalTensor<float> o32_prev_ub_tensor = buf.GetBuffer<BufferType::ASCEND_UB, float>(lo_ubuf_offset); // o_prev搬入ub的变量准备

    AscendC::GlobalTensor<half> mask_gm_tensor;
    AscendC::GlobalTensor<uint8_t> mask_u8_gm_tensor;
    AscendC::GlobalTensor<half> o_gm_tensor;
    AscendC::GlobalTensor<half> s_gm_tensor;
    AscendC::GlobalTensor<half> p_gm_tensor;
    AscendC::GlobalTensor<float> o_tmp_gm_tensor;
    AscendC::GlobalTensor<float> upo_gm_tensor;

    AscendC::GlobalTensor<float> lse_gm_tensor; // change
    AscendC::GlobalTensor<float> lse_prev_gm_tensor; // change
    AscendC::GlobalTensor<half> o_prev_gm_tensor; // change

    mask_u8_gm_tensor.SetGlobalBuffer(mask_gm);
    mask_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(mask_gm));
    o_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(o_gm));
    s_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(s_gm));
    p_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(p_gm));
    o_tmp_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(o_tmp_gm));
    upo_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(upo_tmp_gm));

    lse_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(lse_gm)); // change
    o_prev_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ half *>(o_prev)); // change
    lse_prev_gm_tensor.SetGlobalBuffer(reinterpret_cast<__gm__ float *>(lse_prev)); // change

    uint32_t go_flag_scalar = 1;
    uint32_t batch_size = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm));
    uint32_t max_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 1));
    uint32_t q_heads = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 2));
    uint32_t embd = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 3));
    uint32_t embdv = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 23));
    half tor = (half)(*((__gm__ float *)tiling_para_gm + 5));
    uint32_t head_stride = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 6));
    uint32_t mask_stride = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 7));
    uint32_t is_triu_mask = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 8));
    uint32_t total_q_blk_num = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 9));
    uint32_t isClamp = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 10));
    half clampMin = (half)(*((__gm__ float *)tiling_para_gm + 11));
    half clampMax = (half)(*((__gm__ float *)tiling_para_gm + 12));
    uint32_t tiling_head_size = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 14));
    uint32_t tiling_para_size = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 15));
    uint32_t long_seq = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 17));
    uint32_t mask_type = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 20));
    uint32_t isRing = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 37));

    uint32_t n_tokens = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 38));

    uint32_t data_shape_type =(uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 24));
    uint64_t stride_qo = q_heads * embdv;

    if(data_shape_type == 1){
        stride_qo = embdv;
    }
    uint32_t loopV = (embdv + BLOCK_QK - 1) / BLOCK_QK;
    uint32_t qk_k = BLOCK_QK;
    uint32_t qk_round_k = BLOCK_QK;

    constexpr int32_t BLOCK_SIZE_32 = 32;
    static constexpr uint32_t T_BLOCK_SIZE =  BLOCK_SIZE_32 / sizeof(float);
    uint32_t __k{0};
    uint32_t round_k{0};

    __k = embdv;
    round_k = RoundUp<T_BLOCK_SIZE>(__k);

    uint32_t lenBurst = sizeof(float);


    SET_FLAG(MTE3, MTE2, EVENT_ID0);
    SET_FLAG(MTE3, MTE2, EVENT_ID1);
    SET_FLAG(MTE3, MTE2, EVENT_ID2);
    SET_FLAG(V, MTE2, EVENT_ID0);
    SET_FLAG(V, MTE2, EVENT_ID1);
    SET_FLAG(V, MTE2, EVENT_ID2);
    SET_FLAG(V, MTE2, EVENT_ID3);
    SET_FLAG(V, MTE2, EVENT_ID4);
    SET_FLAG(V, MTE2, EVENT_ID5);
    SET_FLAG(MTE3, V, EVENT_ID0);
    SET_FLAG(MTE3, V, EVENT_ID1);

    uint64_t cur_batch = 0;
    uint32_t pre_total_q_blk_num = 0;
    uint32_t offset_tiling = tiling_head_size + tiling_para_size * cur_batch;
    uint32_t cur_total_q_blk_num = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 13 + offset_tiling));
    uint32_t process_num = total_q_blk_num * q_heads;
    uint32_t next_process = 0;
    for (uint32_t process = block_idx; process < process_num; process = next_process) { // process_num: batch *(qSeqlen/mUbd) *q_heads
        while (process >= cur_total_q_blk_num * q_heads) {
            cur_batch++;
            pre_total_q_blk_num = cur_total_q_blk_num;
            offset_tiling += tiling_para_size;
            cur_total_q_blk_num = (uint32_t)(*((__gm__ uint32_t *)tiling_para_gm + 13 + offset_tiling));
        }
        next_process = process + block_num;
        if (is_triu_mask) {
            uint32_t curr_iter = process / block_num;
            next_process = curr_iter % 2 == 1 ? (curr_iter + 1) * block_num + block_idx : (curr_iter + 2) * block_num - 1 - block_idx;
        }

        // get tiling args
        uint32_t q_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + offset_tiling));
        uint32_t kv_seqlen = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 1 + offset_tiling));
        if (q_seqlen == 0 || kv_seqlen == 0) {
            continue;
        }
        uint32_t pp_m_scalar = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 2 + offset_tiling));
        uint32_t pp_n_scalar = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 3 + offset_tiling));
        uint32_t addr_o_high32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 10 + offset_tiling)); // high32 ？？
        uint32_t addr_o_loww32 = (uint32_t)(*((__gm__ int32_t *)tiling_para_gm + 11 + offset_tiling));
        uint64_t addr_o_scalar = (uint64_t)(((uint64_t)addr_o_high32) << 32 | addr_o_loww32);

        uint32_t process_idx = process - pre_total_q_blk_num * q_heads;
        uint32_t m_idx = process_idx / q_heads; // 按照head分块？
        uint64_t head_idx = process_idx % q_heads; //

        // for prefix triu_mask
        uint32_t prefixLen = kv_seqlen - q_seqlen;
        uint32_t prefixBlockNum = (prefixLen + pp_m_scalar - 1) / pp_m_scalar;

        uint32_t m_loop = (q_seqlen + pp_m_scalar - 1) / pp_m_scalar; // m_loop:q_seqlen维度切分
        uint32_t n_loop = (kv_seqlen + pp_n_scalar - 1) / pp_n_scalar;// n_loop：kv_seqlen维度切分

        uint32_t qk_m = (m_idx == (m_loop - 1)) ? (q_seqlen - m_idx * pp_m_scalar) : pp_m_scalar;
        uint32_t sub_m = (sub_block_idx == 1) ? (qk_m - qk_m / 2) : qk_m / 2;
        uint32_t sub_m_d128 = (sub_m + VECTOR_SIZE - 1) / VECTOR_SIZE;             // up aligned to 128
        uint32_t sub_m_d64 = (sub_m + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE;  // up aligned to 64
        uint32_t round_sub_m = (sub_m + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;  // up aligned to  4 * 16  == 64

        /******** pre_load *******/
        uint32_t qk_n = n_loop == 1 ? kv_seqlen : pp_n_scalar;
        uint32_t qk_round_n = (qk_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;

        uint32_t pingpong_flag = 0;
        uint32_t offset = pingpong_flag * UB_HALF_BUF_SIZE;
        uint64_t mask_batch_offset = cur_batch * mask_stride * max_seqlen;
        uint64_t mask_head_offset = head_idx * ((uint64_t)head_stride) * max_seqlen;
        uint64_t mask_offset = mask_batch_offset + mask_head_offset;
        if (long_seq == 0) {
            mask_offset += m_idx * pp_m_scalar * max_seqlen + prefixLen * max_seqlen;
        } else {
            gm_to_ub<ArchType::ASCEND_V220, half>(
                mask_ubuf_tensor,
                mask_gm_tensor[(uint64_t)sub_block_idx * qk_m / 2 * VECTOR_SIZE],
                0,                                // sid
                sub_m,                                // nBurst
                VECTOR_SIZE / BLOCK_SIZE,  // lenBurst
                0,                                // srcGap
                0                                 // dstGap
            );
            SET_FLAG(MTE2, V, EVENT_ID0);
            WAIT_FLAG(MTE2, V, EVENT_ID0);
        }

        uint64_t o_offset = addr_o_scalar + head_idx * embdv + m_idx * pp_m_scalar * stride_qo;
        uint64_t lse_offset = head_idx * n_tokens + addr_o_scalar / q_heads / embdv + m_idx * pp_m_scalar;  //

        if(data_shape_type == 1){
            o_offset = addr_o_scalar + head_idx * embdv * max_seqlen + m_idx * pp_m_scalar * stride_qo;
        }

        uint32_t n_end = n_loop;
        if (is_triu_mask) {
            n_end = m_idx + prefixBlockNum + 1;
        }
        uint32_t qk_n_triu = n_end * pp_n_scalar;
        uint32_t s_block_stack = n_end > NO_STACK_S_BLOCK_LIMIT ? 2 : 1;
        uint32_t launch_delay = s_block_stack * 2;
        uint32_t vect_mod = 2 * launch_delay;
        uint32_t m_slice = sub_m > 32 ? 32 : 0; // s_block_stack=2时，UB可以放下
        uint32_t m_end = sub_m > 32 ? 2 : 1;

        for (uint32_t n_idx = 0; n_idx < n_end + launch_delay; n_idx += s_block_stack) { // n_loop循环--kvlen维度，每次处理s_block_stack 2/1
            if (n_idx < n_end) { // qk部分
                if (n_idx + s_block_stack > n_end - 1) { // 尾块处理
                    qk_n = qk_n_triu > kv_seqlen ? kv_seqlen - n_idx * pp_n_scalar : qk_n_triu - n_idx * pp_n_scalar;
                } else {
                    qk_n = pp_n_scalar * s_block_stack;
                }
                qk_round_n = (qk_n + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;
                if (sub_m > 0 && mask_type != 0 && long_seq == 0) {
                    if (qk_n <= pp_n_scalar) {
                        pingpong_flag = n_idx % 2;
                        offset = pingpong_flag * UB_HALF_BUF_SIZE;
                        WAIT_FLAG(V, MTE2, pingpong_flag + 2);
                        gm_to_ub_align<ArchType::ASCEND_V220, half>(
                            mask_ubuf_tensor[offset],
                            mask_gm_tensor[mask_offset + (uint64_t)sub_block_idx * qk_m / 2 * max_seqlen],
                            0,                            // sid
                            sub_m,                        // nBurst
                            qk_n * 2,                // lenBurst
                            0,                            // leftPaddingNum
                            0,                            // rightPaddingNum
                            (max_seqlen - qk_n) * 2, // srcGap
                            0                             // dstGap
                        );
                        SET_FLAG(MTE2, V, pingpong_flag + 2);
                    } else {
                        WAIT_FLAG(V, MTE2, EVENT_ID2);
                        gm_to_ub_align<ArchType::ASCEND_V220, half>(
                            mask_ubuf_tensor,
                            mask_gm_tensor[mask_offset + (uint64_t)sub_block_idx * qk_m / 2 * max_seqlen],
                            0,                            // sid
                            sub_m,                        // nBurst
                            qk_n * 2,                // lenBurst
                            0,                            // leftPaddingNum
                            0,                            // rightPaddingNum
                            (max_seqlen - qk_n) * 2, // srcGap
                            0                             // dstGap
                        );
                        SET_FLAG(MTE2, V, EVENT_ID2);
                    }
                    mask_offset += qk_n;
                }
                WaitFlagDev(QK_READY);
                uint32_t qk_n_reduce_sum = qk_n / FLOAT_VECTOR_SIZE * FLOAT_VECTOR_SIZE;
                if (qk_n <= VECTOR_SIZE) {
                    pingpong_flag = n_idx % 2;
                    offset = pingpong_flag * UB_HALF_BUF_SIZE;
                    if (sub_m > 0) {
                        // int32_t
                        WAIT_FLAG(MTE3, MTE2, pingpong_flag);
                        if (s_block_stack == 2) {
                            WAIT_FLAG(MTE3, MTE2, 1 - pingpong_flag);
                        }
                        // input QK
                        gm_to_ub<ArchType::ASCEND_V220, half>(
                            ls_ubuf_tensor[offset],
                            s_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod +
                                (uint64_t)sub_block_idx * qk_m / 2 * qk_round_n],
                            0,                                // sid
                            sub_m,                                // nBurst
                            qk_round_n / BLOCK_SIZE,  // lenBurst
                            0,                                // srcGap
                            0                                 // dstGap
                        );
                        SET_FLAG(MTE2, V, EVENT_ID0);
                        WAIT_FLAG(MTE2, V, EVENT_ID0);
                        // *** ls = tor * ls
                        muls_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset],
                            ls_ubuf_tensor[offset],
                            tor,
                            (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE,  // repeat
                            1,                                                     // dstBlockStride
                            1,                                                     // srcBlockStride
                            8,                                                     // dstRepeatStride
                            8                                                      // srcRepeatStride
                        );
                        PIPE_BARRIER(V);
                        if (isClamp == 1){
                            // get min(clampMin，ls_ubuf)
                            maxs_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset],
                                ls_ubuf_tensor[offset],
                                clampMin,
                                (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                1,                     // dstBlockStride
                                1,                     // srcBlockStride
                                8,                     // dstRepeatStride
                                8                      // srcRepeatStride
                            );
                            PIPE_BARRIER(V);

                            // get max(clampMin，ls_ubuf)
                            mins_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset],
                                ls_ubuf_tensor[offset],
                                clampMax,
                                (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                1,                     // dstBlockStride
                                1,                     // srcBlockStride
                                8,                     // dstRepeatStride
                                8                      // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                        }
                        // *** ls = ls + mask
                        if (mask_type != 0) {
                            if (long_seq == 0) {
                                WAIT_FLAG(MTE2, V, pingpong_flag + 2);
                                add_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset], ls_ubuf_tensor[offset],
                                    mask_ubuf_tensor[offset],
                                    (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                    1,                                                    // dstBlockStride
                                    1,                                                    // src0BlockStride
                                    1,                                                    // src1BlockStride
                                    8,                                                    // dstRepeatStride
                                    8,                                                    // src0RepeatStride
                                    8                                                     // src1RepeatStride
                                );
                                SET_FLAG(V, MTE2, pingpong_flag + 2);
                             } else if (pp_n_scalar == FLOAT_VECTOR_SIZE && s_block_stack == 2 && n_idx == n_end - 2) {
                                __set_mask(qk_n - FLOAT_VECTOR_SIZE);
                                add_v<ArchType::ASCEND_V220, half>(
                                    ls_ubuf_tensor[offset + FLOAT_VECTOR_SIZE],
                                    ls_ubuf_tensor[offset + FLOAT_VECTOR_SIZE],
                                    mask_ubuf_tensor,
                                    sub_m, // repeat
                                    1,                                                                // dstBlockStride
                                    1,                                                                // src0BlockStride
                                    1,                                                                // src1BlockStride
                                    qk_round_n / BLOCK_SIZE,                                                                // dstRepeatStride
                                    qk_round_n / BLOCK_SIZE,                                                                // src0RepeatStride
                                    8                                                                 // src1RepeatStride
                                );
                            } else if (n_idx == n_end - 1) {
                                __set_mask(qk_n);
                                add_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset], ls_ubuf_tensor[offset],
                                    mask_ubuf_tensor,
                                    sub_m,                                                 // repeat
                                    1,                                                    // dstBlockStride
                                    1,                                                    // src0BlockStride
                                    1,                                                    // src1BlockStride
                                    qk_round_n / BLOCK_SIZE,                              // dstRepeatStride
                                    qk_round_n / BLOCK_SIZE,                              // src0RepeatStride
                                    8                                                     // src1RepeatStride
                                );
                            }
                            PIPE_BARRIER(V);
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        }
                        // *** lm = rowmax(ls)
                        if (qk_n <= VECTOR_SIZE) {
                            __set_mask(qk_n);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                ls_ubuf_tensor[offset],
                                sub_m,
                                2,
                                1,
                                qk_round_n / BLOCK_SIZE
                            );
                            PIPE_BARRIER(V);
                            __set_vcg_mask(qk_round_n / BLOCK_SIZE);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                lm_ubuf_tensor,
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                (sub_m * BLOCK_SIZE + VECTOR_SIZE - 1) / VECTOR_SIZE,
                                1,
                                1,
                                8
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        } else {
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                ls_ubuf_tensor[offset],
                                sub_m,
                                2,
                                1,
                                qk_round_n / BLOCK_SIZE
                            );
                            PIPE_BARRIER(V);
                            __set_mask(qk_n - VECTOR_SIZE);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                tv_ubuf_tensor.ReinterpretCast<half>()[ROWMAX_TEMP_BUF_OFFSET],
                                ls_ubuf_tensor[offset + VECTOR_SIZE],
                                sub_m,
                                2,
                                1,
                                qk_round_n / BLOCK_SIZE
                            );
                            PIPE_BARRIER(V);
                            __set_vcg_mask((qk_round_n - VECTOR_SIZE) / BLOCK_SIZE);
                            max_v<ArchType::ASCEND_V220, half>(
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                tv_ubuf_tensor.ReinterpretCast<half>()[ROWMAX_TEMP_BUF_OFFSET],
                                (sub_m * BLOCK_SIZE + VECTOR_SIZE - 1) / VECTOR_SIZE,
                                1,                       // dstBlockStride
                                1,                       // src0BlockStride
                                1,                       // src1BlockStride
                                8,                       // dstRepeatStride
                                8, // src0RepeatStride
                                8  // src1RepeatStride
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            PIPE_BARRIER(V);
                            __set_vcg_mask(VECTOR_SIZE / BLOCK_SIZE);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                lm_ubuf_tensor,
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                (sub_m * BLOCK_SIZE + VECTOR_SIZE - 1) / VECTOR_SIZE,
                                1,
                                1,
                                8
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        } // lm_ubuf_tensor中为最大值
                        PIPE_BARRIER(V);
                        if (n_idx == 0) {
                            // *** hm = lm   hm记录最大值
                            ub_to_ub<ArchType::ASCEND_V220, half>(
                                hm_ubuf_tensor,
                                lm_ubuf_tensor,
                                0,                         // sid
                                1,                         // nBurst
                                round_sub_m / BLOCK_SIZE,  // lenBurst
                                0,                         // srcGap
                                0                          // dstGap
                            );
                            PIPE_BARRIER(V);
                        } else {
                            // *** hm = vmax(lm, gm)
                            max_v<ArchType::ASCEND_V220, half>(hm_ubuf_tensor,
                                lm_ubuf_tensor,
                                gm_ubuf_tensor,
                                sub_m_d128,  // repeat
                                1,           // dstBlockStride
                                1,           // src0BlockStride
                                1,           // src1BlockStride
                                8,           // dstRepeatStride
                                8,           // src0RepeatStride
                                8            // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm = gm - hm
                            sub_v<ArchType::ASCEND_V220, half>(dm_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_HALF_LINE_SIZE],
                                gm_ubuf_tensor,
                                hm_ubuf_tensor,
                                sub_m_d128,  // repeat
                                1,           // dstBlockStride
                                1,           // src0BlockStride
                                1,           // src1BlockStride
                                8,           // dstRepeatStride
                                8,           // src0RepeatStride
                                8            // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                        }
                        // *** gm = hm  更新gm为最大值
                        ub_to_ub<ArchType::ASCEND_V220, half>(
                            gm_ubuf_tensor,
                            hm_ubuf_tensor,
                            0,                         // sid
                            1,                         // nBurst
                            round_sub_m / BLOCK_SIZE,  // lenBurst
                            0,                         // srcGap
                            0                          // dstGap
                        );
                        PIPE_BARRIER(V);
                        // *** hm_block = expand_to_block(hm), 存放于 tv
                        brcb_v<ArchType::ASCEND_V220, uint16_t>(
                            tv_ubuf_tensor.ReinterpretCast<uint16_t>(),
                            hm_ubuf_tensor.ReinterpretCast<uint16_t>(),
                            1,                              // dstBlockStride
                            8,                              // dstRepeatStride
                            round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                        );
                        PIPE_BARRIER(V);
                        // *** ls = ls - hm_block
                        for (uint32_t vsub_idx = 0; vsub_idx < qk_n / VECTOR_SIZE; ++vsub_idx) {
                            sub_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset + vsub_idx * VECTOR_SIZE],
                                ls_ubuf_tensor[offset + vsub_idx * VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                sub_m,                    // repeat
                                1,                        // dstBlockStride
                                1,                        // src0BlockStride
                                0,                        // src1BlockStride
                                qk_round_n / BLOCK_SIZE,  // dstRepeatStride
                                qk_round_n / BLOCK_SIZE,  // src0RepeatStride
                                1                         // src1RepeatStride
                            );
                        }
                        if (qk_n % VECTOR_SIZE > 0) {
                            __set_mask(qk_n % VECTOR_SIZE);
                            sub_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[offset + qk_n / VECTOR_SIZE * VECTOR_SIZE],
                                ls_ubuf_tensor[offset + qk_n / VECTOR_SIZE * VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                sub_m,                    // repeat
                                1,                        // dstBlockStride
                                1,                        // src0BlockStride
                                0,                        // src1BlockStride
                                qk_round_n / BLOCK_SIZE,  // dstRepeatStride
                                qk_round_n / BLOCK_SIZE,  // src0RepeatStride
                                1                         // src1RepeatStride
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        }
                        PIPE_BARRIER(V);
                        // *** ls = castfp16to32(ls)
                        conv_v<ArchType::ASCEND_V220, half, float>(ls32_ubuf_tensor,
                            ls_ubuf_tensor[offset],
                            (sub_m * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                            1,                                                                 // dstBlockStride
                            1,                                                                 // srcBlockStride
                            8,                                                                 // dstRepeatStride
                            4                                                                  // srcRepeatStride
                        );
                        PIPE_BARRIER(V);
                        // *** ls = exp(ls)
                        exp_v<ArchType::ASCEND_V220, float>(ls32_ubuf_tensor,
                            ls32_ubuf_tensor,
                            (sub_m * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                            1,                                                                 // dstBlockStride
                            1,                                                                 // srcBlockStride
                            8,                                                                 // dstRepeatStride
                            8                                                                  // srcRepeatStride
                        );
                        PIPE_BARRIER(V);
                        // *** lp = castfp32to16(ls)
                        conv_v<ArchType::ASCEND_V220, float, half>(lp_ubuf_tensor[offset],
                            ls32_ubuf_tensor,
                            (sub_m * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                            1,                                                                 // dstBlockStride
                            1,                                                                 // srcBlockStride
                            4,                                                                 // dstRepeatStride
                            8                                                                  // srcRepeatStride
                        );
                        PIPE_BARRIER(V);
                        SET_FLAG(V, MTE3, EVENT_ID0);
                        // *** ll = rowsum(ls32)
                        if (qk_n <= FLOAT_VECTOR_SIZE) {
                            __set_mask(qk_n);
                            cadd_v<ArchType::ASCEND_V220, float>(ll_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_FLOAT_LINE_SIZE],
                                ls32_ubuf_tensor,
                                sub_m,                          // repeat
                                1,                              // dstRepeatStride
                                1,                              // srcBlockStride
                                qk_round_n / FLOAT_BLOCK_SIZE   // srcRepeatStride
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        } else {
                            for (uint32_t rowsum_idx = 1; rowsum_idx < qk_n / FLOAT_VECTOR_SIZE; ++rowsum_idx) {
                                add_v<ArchType::ASCEND_V220, float>(ls32_ubuf_tensor,
                                    ls32_ubuf_tensor,
                                    ls32_ubuf_tensor[rowsum_idx * FLOAT_VECTOR_SIZE],
                                    sub_m,                          // repeat
                                    1,                              // dstBlockStride
                                    1,                              // src0BlockStride
                                    1,                              // src1BlockStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE   // src1RepeatStride
                                );
                                PIPE_BARRIER(V);
                            }
                            if (qk_n % FLOAT_VECTOR_SIZE > 0) {
                                __set_mask(qk_n % FLOAT_VECTOR_SIZE);
                                add_v<ArchType::ASCEND_V220, float>(ls32_ubuf_tensor,
                                    ls32_ubuf_tensor,
                                    ls32_ubuf_tensor[qk_n / FLOAT_VECTOR_SIZE * FLOAT_VECTOR_SIZE],
                                    sub_m,                          // repeat
                                    1,                              // dstBlockStride
                                    1,                              // src0BlockStride
                                    1,                              // src1BlockStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE   // src1RepeatStride
                                );
                                SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            }
                            PIPE_BARRIER(V);
                            cadd_v<ArchType::ASCEND_V220, float>(ll_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_FLOAT_LINE_SIZE],
                                ls32_ubuf_tensor,
                                sub_m,                          // repeat
                                1,                              // dstRepeatStride
                                1,                              // srcBlockStride
                                qk_round_n / FLOAT_BLOCK_SIZE   // srcRepeatStride
                            );
                        }
                        PIPE_BARRIER(V);
                        if (n_idx == 0) {
                            ub_to_ub<ArchType::ASCEND_V220, float>(
                                gl_ubuf_tensor,
                                ll_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_FLOAT_LINE_SIZE],
                                0,                               // sid
                                1,                               // nBurst
                                round_sub_m / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                               // srcGap
                                0                                // dstGap
                            );
                        } else {
                            conv_v<ArchType::ASCEND_V220, half, float>(tv_ubuf_tensor,
                                dm_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_HALF_LINE_SIZE],
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                4           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm = exp(dm)
                            exp_v<ArchType::ASCEND_V220, float>(tv_ubuf_tensor,
                                tv_ubuf_tensor,
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                8           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm_block = expand_to_block(dm), 存放于 tv
                            brcb_v<ArchType::ASCEND_V220, uint32_t>(tv_ubuf_tensor.ReinterpretCast<uint32_t>()[VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<uint32_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                            );
                            PIPE_BARRIER(V);
                            // *** gl = dm * gl
                            mul_v<ArchType::ASCEND_V220, float>(gl_ubuf_tensor,
                                tv_ubuf_tensor,
                                gl_ubuf_tensor,
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // src0BlockStride
                                1,          // src1BlockStride
                                8,          // dstRepeatStride
                                8,          // src0RepeatStride
                                8           // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** gl = ll + gl
                            add_v<ArchType::ASCEND_V220, float>(gl_ubuf_tensor,
                                gl_ubuf_tensor,
                                ll_ubuf_tensor[(n_idx / s_block_stack) % 4 * UB_FLOAT_LINE_SIZE],
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // src0BlockStride
                                1,          // src1BlockStride
                                8,          // dstRepeatStride
                                8,          // src0RepeatStride
                                8           // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                        }
                        PIPE_BARRIER(V);
                        WAIT_FLAG(V, MTE3, EVENT_ID0);
                        ub_to_gm<ArchType::ASCEND_V220, half>(
                            p_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod +
                                (uint64_t)sub_block_idx * qk_m / 2 * qk_round_n],
                            lp_ubuf_tensor[offset],
                            0,                                // sid
                            1,                                // nBurst
                            sub_m * qk_round_n / BLOCK_SIZE,  // lenBurst
                            0,                                // srcGap
                            0                                 // dstGap
                        );
                        SET_FLAG(MTE3, MTE2, pingpong_flag);
                        if (s_block_stack == 2) {
                            SET_FLAG(MTE3, MTE2, 1 - pingpong_flag);
                        }
                    }
                } else {
                    bool last_n_loop = n_idx + s_block_stack > n_end - 1;
                    if (sub_m > 0) {
                        WAIT_FLAG(MTE3, MTE2, EVENT_ID0);
                        // input QK
                        gm_to_ub<ArchType::ASCEND_V220, half>(
                            ls_ubuf_tensor,
                            s_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod +
                                (uint64_t)sub_block_idx * qk_m / 2 * qk_round_n],
                            0,                                // sid
                            m_slice,                                // nBurst
                            qk_round_n / BLOCK_SIZE,  // lenBurst
                            0,                                // srcGap
                            0                                 // dstGap
                        );
                        if (sub_m > m_slice) {
                            if (m_end > 1) {
                                WAIT_FLAG(MTE3, MTE2, EVENT_ID1);
                            }
                            gm_to_ub<ArchType::ASCEND_V220, half>(
                                ls_ubuf_tensor[m_slice * qk_round_n],
                                s_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod +
                                    (uint64_t)sub_block_idx * qk_m / 2 * qk_round_n + m_slice * qk_round_n],
                                0,                                // sid
                                sub_m - m_slice,                                // nBurst
                                qk_round_n / BLOCK_SIZE,  // lenBurst
                                0,                                // srcGap
                                0                                 // dstGap
                            );
                        }
                        SET_FLAG(MTE2, V, EVENT_ID0);
                        WAIT_FLAG(MTE2, V, EVENT_ID0);
                        // *** ls = tor * ls
                        muls_v<ArchType::ASCEND_V220, half>(
                            ls_ubuf_tensor,
                            ls_ubuf_tensor,
                            tor,
                            (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE,  // repeat
                            1,                                                     // dstBlockStride
                            1,                                                     // srcBlockStride
                            8,                                                     // dstRepeatStride
                            8                                                      // srcRepeatStride
                        );
                        PIPE_BARRIER(V);
                        if (mask_type != 0) {
                            if (long_seq == 0) {
                                WAIT_FLAG(MTE2, V, EVENT_ID2);
                                add_v<ArchType::ASCEND_V220, half>(
                                    ls_ubuf_tensor,
                                    ls_ubuf_tensor,
                                    mask_ubuf_tensor,
                                    (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                    1,                                                    // dstBlockStride
                                    1,                                                    // src0BlockStride
                                    1,                                                    // src1BlockStride
                                    8,                                                    // dstRepeatStride
                                    8,                                                    // src0RepeatStride
                                    8                                                     // src1RepeatStride
                                );
                                SET_FLAG(V, MTE2, EVENT_ID2);
                            } else if (n_idx == n_end - 2) {
                                __set_mask(qk_n - pp_n_scalar);
                                add_v<ArchType::ASCEND_V220, half>(
                                    ls_ubuf_tensor[pp_n_scalar],
                                    ls_ubuf_tensor[pp_n_scalar],
                                    mask_ubuf_tensor,
                                    sub_m,                                                 // repeat
                                    1,                                                    // dstBlockStride
                                    1,                                                    // src0BlockStride
                                    1,                                                    // src1BlockStride
                                    qk_round_n / BLOCK_SIZE,                              // dstRepeatStride
                                    qk_round_n / BLOCK_SIZE,                              // src0RepeatStride
                                    8                                                     // src1RepeatStride
                                );
                                SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            }
                            PIPE_BARRIER(V);
                        }
                        if (isClamp == 1){
                            // get min(clampMin，ls_ubuf)
                            maxs_v<ArchType::ASCEND_V220, half>(
                                ls_ubuf_tensor,
                                ls_ubuf_tensor,
                                clampMin,
                                (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                1,                     // dstBlockStride
                                1,                     // srcBlockStride
                                8,                     // dstRepeatStride
                                8                      // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // get max(clampMin，ls_ubuf)
                            mins_v<ArchType::ASCEND_V220, half>(
                                ls_ubuf_tensor,
                                ls_ubuf_tensor,
                                clampMax,
                                (sub_m * qk_round_n + VECTOR_SIZE - 1) / VECTOR_SIZE, // repeat
                                1,                     // dstBlockStride
                                1,                     // srcBlockStride
                                8,                     // dstRepeatStride
                                8                      // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                        }
                        if (qk_n != SOFTMAX_MAX_LENGTH) {
                            ub_to_ub<ArchType::ASCEND_V220, half>(
                                ls32_ubuf_tensor.ReinterpretCast<half>(),
                                ls_ubuf_tensor,
                                0,                                        // sid
                                sub_m,                                    // nBurst
                                VECTOR_SIZE / BLOCK_SIZE,                 // lenBurst
                                (qk_round_n - VECTOR_SIZE) / BLOCK_SIZE,  // srcGap
                                0                                         // dstGap
                            );
                            PIPE_BARRIER(V);
                            __set_mask(qk_n - VECTOR_SIZE);
                            max_v<ArchType::ASCEND_V220, half>(
                                ls32_ubuf_tensor.ReinterpretCast<half>(),
                                ls32_ubuf_tensor.ReinterpretCast<half>(),
                                ls_ubuf_tensor[VECTOR_SIZE],
                                sub_m,                   // repeat
                                1,                       // dstBlockStride
                                1,                       // src0BlockStride
                                1,                       // src1BlockStride
                                8,                       // dstRepeatStride
                                8, // src0RepeatStride
                                qk_round_n / BLOCK_SIZE  // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                ls32_ubuf_tensor.ReinterpretCast<half>(),
                                sub_m,
                                2,
                                1,
                                8
                            );
                            PIPE_BARRIER(V);
                            __set_vcg_mask(VECTOR_SIZE / BLOCK_SIZE);
                            cgmax_v<ArchType::ASCEND_V220, half>(
                                lm_ubuf_tensor,
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                (sub_m * BLOCK_SIZE + VECTOR_SIZE - 1) / VECTOR_SIZE,
                                1,
                                1,
                                8
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        } else {
                            cgmax_v<ArchType::ASCEND_V220, half>(ls32_ubuf_tensor.ReinterpretCast<half>(),
                                ls_ubuf_tensor,
                                sub_m * qk_round_n / VECTOR_SIZE,
                                1,
                                1,
                                8
                            );
                            PIPE_BARRIER(V);
                            cgmax_v<ArchType::ASCEND_V220, half>(lm_ubuf_tensor,
                                ls32_ubuf_tensor.ReinterpretCast<half>(),
                                (sub_m *  BLOCK_SIZE + VECTOR_SIZE - 1) / VECTOR_SIZE,
                                1,
                                1,
                                8
                            );
                        }
                        PIPE_BARRIER(V);
                        if (n_idx == 0) {
                            // *** hm = lm
                            ub_to_ub<ArchType::ASCEND_V220, half>(
                                gm_ubuf_tensor,
                                lm_ubuf_tensor,
                                0,                         // sid
                                1,                         // nBurst
                                round_sub_m / BLOCK_SIZE,  // lenBurst
                                0,                         // srcGap
                                0                          // dstGap
                            );
                            brcb_v<ArchType::ASCEND_V220, uint16_t>(
                                tv_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                lm_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                            );
                            PIPE_BARRIER(V);
                        } else {
                            // *** hm = vmax(lm, gm)
                            max_v<ArchType::ASCEND_V220, half>(hm_ubuf_tensor,
                                lm_ubuf_tensor,
                                gm_ubuf_tensor,
                                1,  // repeat
                                1,           // dstBlockStride
                                1,           // src0BlockStride
                                1,           // src1BlockStride
                                8,           // dstRepeatStride
                                8,           // src0RepeatStride
                                8            // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** hm_block = expand_to_block(hm), 存放于 tv
                            brcb_v<ArchType::ASCEND_V220, uint16_t>(
                                tv_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                hm_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                            );
                            // *** dm = gm - hm
                            sub_v<ArchType::ASCEND_V220, half>(dm_ubuf_tensor[(n_idx / s_block_stack) % launch_delay * UB_HALF_LINE_SIZE],
                                gm_ubuf_tensor,
                                hm_ubuf_tensor,
                                1,  // repeat
                                1,           // dstBlockStride
                                1,           // src0BlockStride
                                1,           // src1BlockStride
                                8,           // dstRepeatStride
                                8,           // src0RepeatStride
                                8            // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** gm = hm
                            ub_to_ub<ArchType::ASCEND_V220, half>(
                                gm_ubuf_tensor,
                                hm_ubuf_tensor,
                                0,                         // sid
                                1,                         // nBurst
                                round_sub_m / BLOCK_SIZE,  // lenBurst
                                0,                         // srcGap
                                0                          // dstGap
                            );
                            PIPE_BARRIER(V);
                        }
                        // *** ls = ls - hm_block
                        for (uint32_t vsub_idx = 0; vsub_idx < qk_n / VECTOR_SIZE; ++vsub_idx) {
                            sub_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[vsub_idx * VECTOR_SIZE],
                                ls_ubuf_tensor[vsub_idx * VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                sub_m,                    // repeat
                                1,                        // dstBlockStride
                                1,                        // src0BlockStride
                                0,                        // src1BlockStride
                                qk_round_n / BLOCK_SIZE,  // dstRepeatStride
                                qk_round_n / BLOCK_SIZE,  // src0RepeatStride
                                1                         // src1RepeatStride
                            );
                        }
                        if (qk_n % VECTOR_SIZE > 0) {
                            __set_mask(qk_n % VECTOR_SIZE);
                            sub_v<ArchType::ASCEND_V220, half>(ls_ubuf_tensor[qk_n / VECTOR_SIZE * VECTOR_SIZE],
                                ls_ubuf_tensor[qk_n / VECTOR_SIZE * VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<half>(),
                                sub_m,                    // repeat
                                1,                        // dstBlockStride
                                1,                        // src0BlockStride
                                0,                        // src1BlockStride
                                qk_round_n / BLOCK_SIZE,  // dstRepeatStride
                                qk_round_n / BLOCK_SIZE,  // src0RepeatStride
                                1                         // src1RepeatStride
                            );
                            SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                        }
                        PIPE_BARRIER(V);
                        for (uint32_t split_idx = 0; split_idx < m_end; split_idx++) {
                            bool last_m_loop = split_idx == m_end - 1;
                            uint32_t m_split =  last_m_loop ? sub_m - split_idx * m_slice : m_slice;
                            // *** ls = castfp16to32(ls)
                            conv_v<ArchType::ASCEND_V220, half, float>(
                                ls32_ubuf_tensor,
                                ls_ubuf_tensor[split_idx * m_slice * qk_round_n],
                                (m_split * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                                1,                                                                 // dstBlockStride
                                1,                                                                 // srcBlockStride
                                8,                                                                 // dstRepeatStride
                                4                                                                  // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** ls = exp(ls)
                            exp_v<ArchType::ASCEND_V220, float>(
                                ls32_ubuf_tensor,
                                ls32_ubuf_tensor,
                                (m_split * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                                1,                                                                 // dstBlockStride
                                1,                                                                 // srcBlockStride
                                8,                                                                 // dstRepeatStride
                                8                                                                  // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** lp = castfp32to16(ls)
                            conv_v<ArchType::ASCEND_V220, float, half>(
                                lp_ubuf_tensor[split_idx * m_slice * qk_round_n],
                                ls32_ubuf_tensor,
                                (m_split * qk_round_n + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                                1,                                                                 // dstBlockStride
                                1,                                                                 // srcBlockStride
                                4,                                                                 // dstRepeatStride
                                8                                                                  // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            SET_FLAG(V, MTE3, EVENT_ID0);
                            // *** ll = rowsum(ls32)
                            for (uint32_t rowsum_idx = 1; rowsum_idx < qk_n / FLOAT_VECTOR_SIZE; ++rowsum_idx) {
                                add_v<ArchType::ASCEND_V220, float>(ls32_ubuf_tensor,
                                    ls32_ubuf_tensor,
                                    ls32_ubuf_tensor[rowsum_idx * FLOAT_VECTOR_SIZE],
                                    m_split,                          // repeat
                                    1,                              // dstBlockStride
                                    1,                              // src0BlockStride
                                    1,                              // src1BlockStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE   // src1RepeatStride
                                );
                                PIPE_BARRIER(V);
                            }
                            if (qk_n % FLOAT_VECTOR_SIZE > 0) {
                                __set_mask(qk_n % FLOAT_VECTOR_SIZE);
                                add_v<ArchType::ASCEND_V220, float>(ls32_ubuf_tensor,
                                    ls32_ubuf_tensor,
                                    ls32_ubuf_tensor[qk_n_reduce_sum],
                                    m_split,                          // repeat
                                    1,                              // dstBlockStride
                                    1,                              // src0BlockStride
                                    1,                              // src1BlockStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    qk_round_n / FLOAT_BLOCK_SIZE   // src1RepeatStride
                                );
                                SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            }
                            PIPE_BARRIER(V);
                            cadd_v<ArchType::ASCEND_V220, float>(ll_ubuf_tensor[(n_idx / s_block_stack) % launch_delay * UB_FLOAT_LINE_SIZE + split_idx * m_slice],
                                ls32_ubuf_tensor,
                                m_split,                          // repeat
                                1,                              // dstRepeatStride
                                1,                              // srcBlockStride
                                qk_round_n / FLOAT_BLOCK_SIZE   // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            WAIT_FLAG(V, MTE3, EVENT_ID0);
                            ub_to_gm<ArchType::ASCEND_V220, half>(
                                p_gm_tensor[(uint64_t)block_idx * TMP_SIZE + n_idx % vect_mod * TMP_SIZE / vect_mod +
                                    ((uint64_t)sub_block_idx * qk_m / 2 + split_idx * m_slice) * qk_round_n],
                                lp_ubuf_tensor[split_idx * m_slice * qk_round_n],
                                0,                                // sid
                                m_split,                                // nBurst
                                qk_round_n / BLOCK_SIZE,  // lenBurst
                                0,                                // srcGap
                                0                                 // dstGap
                            );
                            SET_FLAG(MTE3, MTE2, split_idx);
                        }
                        PIPE_BARRIER(V);
                        if (n_idx == 0) {
                            ub_to_ub<ArchType::ASCEND_V220, float>(
                                gl_ubuf_tensor,
                                ll_ubuf_tensor[(n_idx / s_block_stack) % launch_delay * UB_FLOAT_LINE_SIZE],
                                0,                               // sid
                                1,                               // nBurst
                                round_sub_m / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                               // srcGap
                                0                                // dstGap
                            );
                        } else {
                            conv_v<ArchType::ASCEND_V220, half, float>(tv_ubuf_tensor,
                                dm_ubuf_tensor[(n_idx / s_block_stack) % launch_delay * UB_HALF_LINE_SIZE],
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                4           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm = exp(dm)
                            exp_v<ArchType::ASCEND_V220, float>(tv_ubuf_tensor,
                                tv_ubuf_tensor,
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                8           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm_block = expand_to_block(dm), 存放于 tv
                            brcb_v<ArchType::ASCEND_V220, uint32_t>(tv_ubuf_tensor.ReinterpretCast<uint32_t>()[VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<uint32_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                            );
                            PIPE_BARRIER(V);
                            // *** gl = dm * gl
                            mul_v<ArchType::ASCEND_V220, float>(gl_ubuf_tensor,
                                tv_ubuf_tensor,
                                gl_ubuf_tensor,
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // src0BlockStride
                                1,          // src1BlockStride
                                8,          // dstRepeatStride
                                8,          // src0RepeatStride
                                8           // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** gl = ll + gl
                            add_v<ArchType::ASCEND_V220, float>(gl_ubuf_tensor,
                                gl_ubuf_tensor,
                                ll_ubuf_tensor[(n_idx / s_block_stack) % launch_delay * UB_FLOAT_LINE_SIZE],
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // src0BlockStride
                                1,          // src1BlockStride
                                8,          // dstRepeatStride
                                8,          // src0RepeatStride
                                8           // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                        }
                    }
                }
                FftsCrossCoreSync<PIPE_MTE3, 2>(SOFTMAX_READY);
            }
            if (n_idx >= launch_delay) {
                // *** 更新 L 和 O
                WaitFlagDev(UPDATE_READY);
                for(uint32_t k_idx = 0; k_idx < loopV; k_idx++){ // (embdv + BLOCK_QK - 1) / BLOCK_QK;
                    uint64_t o_offsetk = o_offset + k_idx * BLOCK_QK;
                    if (sub_m > 0) {
                        qk_k = (k_idx == (loopV - 1))? embdv - k_idx * BLOCK_QK : BLOCK_QK;
                        qk_round_k = (qk_k + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;

                        if(n_idx == launch_delay){
                            WAIT_FLAG(MTE3, MTE2, EVENT_ID2);
                            gm_to_ub<ArchType::ASCEND_V220, float>(
                                go_ubuf_tensor,
                                o_tmp_gm_tensor[(uint64_t)block_idx * TMP_SIZE * LOCAL_SIZE + k_idx * TMP_SIZET  + (n_idx - launch_delay) % vect_mod * TMP_SIZE / vect_mod * loopV+
                                        (uint64_t)sub_block_idx * qk_m / 2 * qk_round_k],
                                0,                                   // sid
                                1,                                   // nBurst
                                sub_m * qk_round_k / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                                   // srcGap
                                0                                    // dstGap
                            );
                            SET_FLAG(MTE2, V, EVENT_ID3);
                            WAIT_FLAG(MTE2, V, EVENT_ID3);
                        }
                        else{
                            WAIT_FLAG(MTE3, MTE2, EVENT_ID2);
                            gm_to_ub<ArchType::ASCEND_V220, float>(
                                go_ubuf_tensor,
                                upo_gm_tensor[(uint64_t)block_idx * TMP_SIZE + k_idx * TMP_SIZET +
                                        (uint64_t)sub_block_idx * qk_m / 2 * qk_round_k],
                                0,                                   // sid
                                1,                                   // nBurst
                                sub_m * qk_round_k / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                                   // srcGap
                                0                                    // dstGap
                            );
                            SET_FLAG(MTE2, V, EVENT_ID3);

                            WAIT_FLAG(V, MTE2, EVENT_ID4);
                            gm_to_ub<ArchType::ASCEND_V220, float>(
                                lo_ubuf_tensor,
                                o_tmp_gm_tensor[(uint64_t)block_idx * TMP_SIZE * LOCAL_SIZE + k_idx * TMP_SIZET  + (n_idx - launch_delay) % vect_mod * TMP_SIZE / vect_mod * loopV +
                                        (uint64_t)sub_block_idx * qk_m / 2 * qk_round_k],
                                0,                                   // sid
                                1,                                   // nBurst
                                sub_m * qk_round_k / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                                   // srcGap
                                0                                    // dstGap
                            );
                            SET_FLAG(MTE2, V, EVENT_ID4);

                            PIPE_BARRIER(V);
                            conv_v<ArchType::ASCEND_V220, half, float>(tv_ubuf_tensor,
                                dm_ubuf_tensor[((n_idx - launch_delay) / s_block_stack % 4)  * UB_HALF_LINE_SIZE],
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                4           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm = exp(dm)
                            exp_v<ArchType::ASCEND_V220, float>(tv_ubuf_tensor,
                                tv_ubuf_tensor,
                                sub_m_d64,  // repeat
                                1,          // dstBlockStride
                                1,          // srcBlockStride
                                8,          // dstRepeatStride
                                8           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** dm_block = expand_to_block(dm), 存放于 tv
                            brcb_v<ArchType::ASCEND_V220, uint32_t>(tv_ubuf_tensor.ReinterpretCast<uint32_t>()[VECTOR_SIZE],
                                tv_ubuf_tensor.ReinterpretCast<uint32_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat  1
                            );
                            PIPE_BARRIER(V);
                            WAIT_FLAG(MTE2, V, EVENT_ID3);
                            // *** go = go * dm_block
                            for (uint32_t vmul_idx = 0; vmul_idx < qk_k / FLOAT_VECTOR_SIZE; ++vmul_idx) { //
                                mul_v<ArchType::ASCEND_V220, float>(go_ubuf_tensor[vmul_idx * FLOAT_VECTOR_SIZE],
                                    go_ubuf_tensor[vmul_idx * FLOAT_VECTOR_SIZE],
                                    tv_ubuf_tensor[VECTOR_SIZE],
                                    sub_m,                       // repeat
                                    1,                           // dstBlockStride
                                    1,                           // src0BlockStride
                                    0,                           // src1BlockStride
                                    qk_round_k / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_k / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    1                            // src1RepeatStride
                                );
                            }
                            if (qk_k % FLOAT_VECTOR_SIZE > 0) {
                                __set_mask(qk_k % FLOAT_VECTOR_SIZE);
                                mul_v<ArchType::ASCEND_V220, float>(go_ubuf_tensor[qk_k / FLOAT_VECTOR_SIZE * FLOAT_VECTOR_SIZE],
                                    go_ubuf_tensor[qk_k / FLOAT_VECTOR_SIZE * FLOAT_VECTOR_SIZE],
                                    tv_ubuf_tensor[VECTOR_SIZE],
                                    sub_m,                       // repeat
                                    1,                           // dstBlockStride
                                    1,                           // src0BlockStride
                                    0,                           // src1BlockStride
                                    qk_round_k / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_k / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                    1                            // src1RepeatStride
                                );
                                SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            }
                            PIPE_BARRIER(V);

                            WAIT_FLAG(MTE2, V, EVENT_ID4);
                            // *** go = lo + go
                            add_v<ArchType::ASCEND_V220, float>(go_ubuf_tensor,
                                go_ubuf_tensor,
                                lo_ubuf_tensor,
                                (sub_m * qk_round_k + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                                1,                                                              // dstBlockStride
                                1,                                                              // src0BlockStride
                                1,                                                              // src1BlockStride
                                8,                                                              // dstRepeatStride
                                8,                                                              // src0RepeatStride
                                8                                                               // src1RepeatStride
                            );
                            PIPE_BARRIER(V);
                            SET_FLAG(V, MTE2, EVENT_ID4);
                        }
                        // *** gl = castfp32to16(gl)
                        if (n_idx + s_block_stack > n_end + launch_delay - 1){ // 结束时候

                            PIPE_BARRIER(V);
                            //以下为o输出的原始代码
                            if(k_idx == 0){
                                conv_v<ArchType::ASCEND_V220, float, half>(gl_ubuf_tensor.ReinterpretCast<half>(),
                                    gl_ubuf_tensor,
                                    sub_m_d64,  // repeat
                                    1,          // dstBlockStride
                                    1,          // srcBlockStride
                                    4,          // dstRepeatStride
                                    8           // srcRepeatStride
                                );
                            }
                            PIPE_BARRIER(V);
                            // *** go = castfp32to16(go)
                            conv_v<ArchType::ASCEND_V220, float, half>(go_ubuf_tensor.ReinterpretCast<half>(),
                                go_ubuf_tensor,
                                (sub_m * qk_round_k + FLOAT_VECTOR_SIZE - 1) / FLOAT_VECTOR_SIZE,  // repeat
                                1,                                                              // dstBlockStride
                                1,                                                              // srcBlockStride
                                4,                                                              // dstRepeatStride
                                8                                                               // srcRepeatStride
                            );
                            PIPE_BARRIER(V);
                            // *** gl_block = expand_to_block(gl), 存放于 tv
                            brcb_v<ArchType::ASCEND_V220, uint16_t>(tv_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                gl_ubuf_tensor.ReinterpretCast<uint16_t>(),
                                1,                              // dstBlockStride
                                8,                              // dstRepeatStride
                                round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                            );
                            PIPE_BARRIER(V);
                            // *** go = go / gl_block
                            for (uint32_t vdiv_idx = 0; vdiv_idx < qk_k / VECTOR_SIZE; ++vdiv_idx) {
                                div_v<ArchType::ASCEND_V220, half>(go_ubuf_tensor.ReinterpretCast<half>()[vdiv_idx * VECTOR_SIZE],
                                    go_ubuf_tensor.ReinterpretCast<half>()[vdiv_idx * VECTOR_SIZE],
                                    tv_ubuf_tensor.ReinterpretCast<half>(),
                                    sub_m,                 // repeat
                                    1,                     // dstBlockStride
                                    1,                     // src0BlockStride
                                    0,                     // src1BlockStride
                                    qk_round_k / BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_k / BLOCK_SIZE,  // src0RepeatStride
                                    1                      // src1RepeatStride
                                );
                            }
                            if (qk_k % VECTOR_SIZE > 0) {
                                __set_mask(qk_k % VECTOR_SIZE);
                                div_v<ArchType::ASCEND_V220, half>(go_ubuf_tensor.ReinterpretCast<half>()[qk_k / VECTOR_SIZE * VECTOR_SIZE],
                                    go_ubuf_tensor.ReinterpretCast<half>()[qk_k / VECTOR_SIZE * VECTOR_SIZE],
                                    tv_ubuf_tensor.ReinterpretCast<half>(),
                                    sub_m,                 // repeat
                                    1,                     // dstBlockStride
                                    1,                     // src0BlockStride
                                    0,                     // src1BlockStride
                                    qk_round_k / BLOCK_SIZE,  // dstRepeatStride
                                    qk_round_k / BLOCK_SIZE,  // src0RepeatStride
                                    1                      // src1RepeatStride
                                );
                                SetVectorMask<int8_t>((uint64_t)-1, (uint64_t)-1);
                            }
                            PIPE_BARRIER(V);
                            // ********************* move O to GM ************************
                            conv_v<ArchType::ASCEND_V220, half, float>(lse32_ubuf_tensor,
                                                                        gl_ubuf_tensor.ReinterpretCast<half>(),
                                                                        sub_m_d64,  // repeat
                                                                        1,          // dstBlockStride
                                                                        1,          // srcBlockStride
                                                                        8,          // dstRepeatStride
                                                                        4           // srcRepeatStride
                                                                        );
                            PIPE_BARRIER(V);
                            conv_v<ArchType::ASCEND_V220, half, float>(lse32_cur_update_tensor,
                                                                        gm_ubuf_tensor,
                                                                        sub_m_d64,  // repeat
                                                                        1,          // dstBlockStride
                                                                        1,          // srcBlockStride
                                                                        8,          // dstRepeatStride
                                                                        4           // srcRepeatStride
                                                                        );
                            PIPE_BARRIER(V);

                            // out lse ---->  out_lse = np.log(score_sum) + score_max
                            ln_v<ArchType::ASCEND_V220, float>(lse32_ubuf_tensor, //参数已确认
                                                               lse32_ubuf_tensor,
                                                               sub_m_d64,  // repeat  1
                                                               1,          // dstBlockStride
                                                               1,          // srcBlockStride
                                                               8,          // dstRepeatStride
                                                               8           // srcRepeatStride
                            );
                            PIPE_BARRIER(V);

                            add_v<ArchType::ASCEND_V220, float>(lse32_ubuf_tensor, //参数已确认
                                                                lse32_ubuf_tensor,
                                                                lse32_cur_update_tensor,
                                                                sub_m_d64,  // repeat
                                                                1,          // dstBlockStride
                                                                1,          // src0BlockStride
                                                                1,          // src1BlockStride
                                                                8,          // dstRepeatStride
                                                                8,          // src0RepeatStride
                                                                8           // src1RepeatStride
                            );
                            PIPE_BARRIER(V);

//                                SET_FLAG(V, MTE2, EVENT_ID5);
                            if (isRing){
//                              以下为更新lse的部分：lse_new = log(exp(lse_new) + exp(lse_old))
//                              搬运prev_lse    lsein_ubuf_tensor

//                                PIPE_BARRIER(ALL);
                                WAIT_FLAG(V, MTE2, EVENT_ID5);
                                gm_to_ub_align<ArchType::ASCEND_V220, float>( // 直接搬入报错error，暂时修改回原版本，待优化
                                    lse32_prev_ub_tensor,
                                    lse_prev_gm_tensor[(lse_offset + (uint64_t)sub_block_idx * qk_m/2)],
                                    0,                                // sid
                                    1,                                // nBurst 64
                                    sub_m * lenBurst,                 // lenBurst   单位byte 64*2 128
                                    0,
                                    0,
                                    0,        // srcGap  (stride_qo - embdv) * 2 / embdv
                                    0                                 // dstGap
                                );
                                SET_FLAG(MTE2, V, EVENT_ID5);
                                WAIT_FLAG(MTE2, V, EVENT_ID5);

                                PIPE_BARRIER(V);

                                // exp(lse_prev) e的指数次结果存放到lse_prev_update_tensor
                                PIPE_BARRIER(V);
                                exp_v<ArchType::ASCEND_V220, float>(lse32_conv_ubuf_tensor,  //float 改为了half
                                                                    lse32_prev_ub_tensor,
                                                                    sub_m_d64,  // repeat
                                                                    1,          // dstBlockStride
                                                                    1,          // srcBlockStride
                                                                    8,          // dstRepeatStride
                                                                    8           // srcRepeatStride
                                );

                                PIPE_BARRIER(V);
                                // exp(lse_new) e的指数次结果存放到lse32_ubuf_tensor
                                exp_v<ArchType::ASCEND_V220, float>(lse32_ubuf_tensor,
                                                                   lse32_ubuf_tensor,
                                                                    sub_m_d64,  // repeat
                                                                    1,          // dstBlockStride
                                                                    1,          // srcBlockStride
                                                                    8,          // dstRepeatStride
                                                                    8           // srcRepeatStride
                                );
                                // 做加法并求log  exp(lse_new) + exp(lse_prev), 存放到lse_prev32
                                PIPE_BARRIER(V);
                                add_v<ArchType::ASCEND_V220, float>(lse32_cur_update_tensor,
                                                                   lse32_ubuf_tensor,
                                                                   lse32_conv_ubuf_tensor,
                                                                   sub_m_d64,  // repeat
                                                                   1,          // dstBlockStride
                                                                   1,          // src0BlockStride
                                                                   1,          // src1BlockStride
                                                                   8,          // dstRepeatStride
                                                                   8,          // src0RepeatStride
                                                                   8           // src1RepeatStride
                                );
                                PIPE_BARRIER(V);
                                ln_v<ArchType::ASCEND_V220, float>(lse32_cur_update_tensor,
                                                                   lse32_cur_update_tensor,
                                                                   sub_m_d64,  // repeat
                                                                   1,          // dstBlockStride
                                                                   1,          // srcBlockStride
                                                                   8,          // dstRepeatStride
                                                                   8           // srcRepeatStride
                                );
                                PIPE_BARRIER(V);
//                                 lse的更新结果搬出   当前精度已验证
                                //*********************************************
                                if (k_idx == 0) {
                                    SET_FLAG(V, MTE3, EVENT_ID4);
                                    WAIT_FLAG(V, MTE3, EVENT_ID4);
                                    ub_to_gm_align<ArchType::ASCEND_V220, float>(
                                        lse_gm_tensor[(lse_offset + (uint64_t)sub_block_idx * qk_m / 2)],                     // 128/2   * embdv
                                        lse32_cur_update_tensor, // ls32_ubuf_tensor.ReinterpretCast<half>()
                                        0,                                        // sid
                                        1,                                        // nBurst
                                        sub_m * lenBurst,                        //(sub_m + 15) / 16,lenBurst  2*64
                                        0,                                        // leftPaddingNum
                                        0,                                        // rightPaddingNum
                                        0,                                        // srcGap
                                        0           // dstGap   512-128
                                    );
                                    SET_FLAG(MTE3, V, EVENT_ID4);
                                    WAIT_FLAG(MTE3, V, EVENT_ID4);
                                }
                                //****************************************以下输出O更新代码********************************************/
                                // 输出o更新部分----o = sum(lse_exp/sum(lse_exp)*oi)
                                // 输出o的更新分析： new_o = (old_o * e(old_lse) + new_o * e(new_lse)) / (e(old_lse) + e(new_lse))
                                // 基础运算过程编写完毕，数据运算类型以及各运算块的偏移等参数需重新填写校对
                                conv_v<ArchType::ASCEND_V220, half, float>(o32_prev_ub_tensor,
                                                                            go_ubuf_tensor.ReinterpretCast<half>(),
                                                                            sub_m * qk_round_k / 64,  // repeat
                                                                            1,          // dstBlockStride
                                                                            1,          // srcBlockStride
                                                                            8,          // dstRepeatStride
                                                                            4           // srcRepeatStride
                                                                            );
                                PIPE_BARRIER(V);

                                // 对应乘积 new_o * e(new_lse) 存放 --> new_o
                                brcb_v<ArchType::ASCEND_V220, uint32_t>(tv_ubuf_tensor.ReinterpretCast<uint32_t>(),
                                                                    lse32_ubuf_tensor.ReinterpretCast<uint32_t>(),
                                                                    1,                              // dstBlockStride
                                                                    8,                              // dstRepeatStride  ori is 8
                                                                    round_sub_m / FLOAT_BLOCK_SIZE // repeat  8   round_sub_m=64   FLOAT_BLOCK_SIZE=8
                                );
                                PIPE_BARRIER(V);
                                //                                WAIT_FLAG(MTE2, V, EVENT_ID3);
                                for (uint32_t vmul_idx = 0; vmul_idx < ((qk_k + FLOAT_VECTOR_SIZE-1) / FLOAT_VECTOR_SIZE); ++vmul_idx) {
                                    mul_v<ArchType::ASCEND_V220, float>(go_ubuf_tensor[vmul_idx * FLOAT_VECTOR_SIZE],  //  FLOAT_VECTOR_SIZE==64
                                                                        o32_prev_ub_tensor[vmul_idx * FLOAT_VECTOR_SIZE], // 0-64     64-?
                                                                        tv_ubuf_tensor,
                                                                        sub_m,                       // repeat
                                                                        1,                           // dstBlockStride
                                                                        1,                           // src0BlockStride
                                                                        0,                           // src1BlockStride
                                                                        qk_round_k / FLOAT_BLOCK_SIZE,  // dstRepeatStride
                                                                        qk_round_k / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                                                        1                            // src1RepeatStride
                                    );
                                }

                                // prev_o搬入ub  ----
                                WAIT_FLAG(V, MTE2, EVENT_ID4);
                                gm_to_ub_align<ArchType::ASCEND_V220, half>(
                                    o_prev_ub_tensor, // 复用lo
                                    o_prev_gm_tensor[o_offsetk + (uint64_t)sub_block_idx * qk_m / 2 * stride_qo],
                                    0,        // sid
                                    sub_m,    // nBurst
                                    qk_k * 2, // lenBurst   单位byte
                                    0, 0,
                                    (stride_qo - qk_k) * 2, // srcGap
                                    0                       // dstGap
                                );
                                SET_FLAG(MTE2, V, EVENT_ID4);
                                WAIT_FLAG(MTE2, V, EVENT_ID4);

                                conv_v<ArchType::ASCEND_V220, half, float>(o32_prev_ub_tensor,
                                                                            o_prev_ub_tensor,
                                                                            sub_m * qk_round_k / 64,  // repeat
                                                                            1,          // dstBlockStride
                                                                            1,          // srcBlockStride
                                                                            8,          // dstRepeatStride
                                                                            4           // srcRepeatStride
                                                                            );
                                PIPE_BARRIER(V);

                                exp_v<ArchType::ASCEND_V220, float>(lse32_prev_ub_tensor,
                                                                   lse32_prev_ub_tensor,
                                                                    sub_m_d64,  // repeat
                                                                    1,          // dstBlockStride
                                                                    1,          // srcBlockStride
                                                                    8,          // dstRepeatStride
                                                                    8           // srcRepeatStride
                                );
                                PIPE_BARRIER(V);

                                brcb_v<ArchType::ASCEND_V220, float>(tv_ubuf_tensor,
                                                                    lse32_prev_ub_tensor,
                                                                    1,                              // dstBlockStride
                                                                    8,                              // dstRepeatStride  ori is 8
                                                                    round_sub_m / FLOAT_BLOCK_SIZE  // repeat  8   round_sub_m=64   FLOAT_BLOCK_SIZE=8
                                );
                                PIPE_BARRIER(V);
                                SET_FLAG(V, MTE2, EVENT_ID5);
                                for (uint32_t vmul_idx = 0; vmul_idx < ((qk_k + FLOAT_VECTOR_SIZE-1) / FLOAT_VECTOR_SIZE); ++vmul_idx) { // FLOAT_VECTOR_SIZE=64  qk_k=128
                                    mul_v<ArchType::ASCEND_V220, float>(o32_prev_ub_tensor[vmul_idx * FLOAT_VECTOR_SIZE],  //FLOAT_VECTOR_SIZE  0     128   256
                                                                       o32_prev_ub_tensor[vmul_idx * FLOAT_VECTOR_SIZE],
                                                                       tv_ubuf_tensor,
                                                                        sub_m,                       // repeat   64
                                                                        1,                           // dstBlockStride
                                                                        1,                           // src0BlockStride
                                                                        0,                           // src1BlockStride
                                                                        qk_round_k / FLOAT_BLOCK_SIZE,  // dstRepeatStride   128 / 16  qk_round_k==128 / FLOAT_BLOCK_SIZE==8
                                                                        qk_round_k / FLOAT_BLOCK_SIZE,  // src0RepeatStride  16
                                                                        1                            // src1RepeatStride
                                    );
                                }
                                PIPE_BARRIER(V);

                                // 求和 old_o * e(old_lse) + new_o * e(new_lse) -- > 存放 old_o
                                PIPE_BARRIER(V);
                                add_v<ArchType::ASCEND_V220, float>(o32_prev_ub_tensor,   // o_prev_ub_tensor
                                                                   o32_prev_ub_tensor,
                                                                   go_ubuf_tensor,
                                                                   sub_m * qk_round_k / 64,  // repeat   1
                                                                   1,          // dstBlockStride
                                                                   1,          // src0BlockStride
                                                                   1,          // src1BlockStride
                                                                   8,          // dstRepeatStride
                                                                   8,          // src0RepeatStride
                                                                   8           // src1RepeatStride
                                );

                                PIPE_BARRIER(V);
                                // (e(old_lse) + e(new_lse)) 做boardcast  --> 存放 new_conv_ubuf_tensor
                                add_v<ArchType::ASCEND_V220, float>(lse32_conv_ubuf_tensor,
                                                                   lse32_ubuf_tensor,
                                                                   lse32_conv_ubuf_tensor,
                                                                   sub_m_d64,  // repeat
                                                                   1,          // dstBlockStride
                                                                   1,          // src0BlockStride
                                                                   1,          // src1BlockStride
                                                                   8,          // dstRepeatStride
                                                                   8,          // src0RepeatStride
                                                                   8           // src1RepeatStride
                                );
                                PIPE_BARRIER(V);

                                // 做除法  old_o * e(old_lse) + new_o * e(new_lse)  /  (e(old_lse) + e(new_lse))
                                brcb_v<ArchType::ASCEND_V220, float>(tv_ubuf_tensor,
                                                                    lse32_conv_ubuf_tensor,
                                                                    1,                              // dstBlockStride
                                                                    8,                              // dstRepeatStride
                                                                    round_sub_m / FLOAT_BLOCK_SIZE  // repeat
                                );
                                PIPE_BARRIER(V);
                                for (uint32_t vdiv_idx = 0; vdiv_idx < ((qk_k + FLOAT_VECTOR_SIZE-1) / FLOAT_VECTOR_SIZE); ++vdiv_idx) {
                                    div_v<ArchType::ASCEND_V220, float>(go_ubuf_tensor[vdiv_idx * FLOAT_VECTOR_SIZE],
                                                                       o32_prev_ub_tensor[vdiv_idx * FLOAT_VECTOR_SIZE],
                                                                       tv_ubuf_tensor,
                                                                       sub_m,                 // repeat
                                                                       1,                     // dstBlockStride
                                                                       1,                     // src0BlockStride
                                                                       0,                     // src1BlockStride
                                                                       qk_round_k / FLOAT_BLOCK_SIZE,  // dstRepeatStride  qk_round_k==128   BLOCK_SIZE=16
                                                                       qk_round_k / FLOAT_BLOCK_SIZE,  // src0RepeatStride
                                                                       1                      // src1RepeatStride
                                    );
                                }
                                PIPE_BARRIER(V);
                                conv_v<ArchType::ASCEND_V220, float, half>(go_ubuf_tensor.ReinterpretCast<half>(),
                                                                    go_ubuf_tensor,
                                                                    sub_m * qk_round_k / 64,  // repeat
                                                                    1,          // dstBlockStride
                                                                    1,          // srcBlockStride
                                                                    4,          // dstRepeatStride
                                                                    8           // srcRepeatStride
                                                                    );
                                PIPE_BARRIER(V);
                                SET_FLAG(V, MTE2, EVENT_ID4);
                                // 搬出O
                                SET_FLAG(V, MTE3, EVENT_ID1);
                                WAIT_FLAG(V, MTE3, EVENT_ID1);
                                ub_to_gm_align<ArchType::ASCEND_V220, half>(
                                    o_gm_tensor[o_offsetk + (uint64_t)sub_block_idx * qk_m / 2 * stride_qo],
                                    go_ubuf_tensor.ReinterpretCast<half>(),      // go_ubuf_tensor.ReinterpretCast<half>()
                                    0,                     // sid
                                    sub_m,                 // nBurst
                                    qk_k * 2,               // lenBurst
                                    0,                     // leftPaddingNum
                                    0,                     // rightPaddingNum
                                    0,                     // srcGap
                                    (stride_qo - qk_k) * 2  // dstGap
                                );
                                SET_FLAG(MTE3, MTE2, EVENT_ID2);

                            } else {
                                PIPE_BARRIER(V);

                                if (k_idx == 0) {
                                    SET_FLAG(V, MTE3, EVENT_ID4);
                                    WAIT_FLAG(V, MTE3, EVENT_ID4);
                                    ub_to_gm_align<ArchType::ASCEND_V220, float>(
                                        lse_gm_tensor[(lse_offset + (uint64_t)sub_block_idx * qk_m / 2)],                     // 128/2   * embdv
                                        lse32_ubuf_tensor, // ls32_ubuf_tensor.ReinterpretCast<half>()
                                        0,                                        // sid
                                        1,                                        // nBurst
                                        sub_m * lenBurst,                        //(sub_m + 15) / 16,lenBurst  64 * 4
                                        0,                                        // leftPaddingNum
                                        0,                                        // rightPaddingNum
                                        0,                                        // srcGap
                                        0                                        // dstGap   512-128
                                    );
                                    SET_FLAG(MTE3, V, EVENT_ID4);
                                    WAIT_FLAG(MTE3, V, EVENT_ID4);
                                }

                                SET_FLAG(V, MTE3, EVENT_ID1);
                                WAIT_FLAG(V, MTE3, EVENT_ID1);
                                ub_to_gm_align<ArchType::ASCEND_V220, half>(
                                    o_gm_tensor[o_offsetk + (uint64_t)sub_block_idx * qk_m / 2 * stride_qo],
                                    go_ubuf_tensor.ReinterpretCast<half>(),
                                    0,                     // sid
                                    sub_m,                 // nBurst
                                    qk_k * 2,               // lenBurst   qk_k = 128
                                    0,                     // leftPaddingNum
                                    0,                     // rightPaddingNum
                                    0,                     // srcGap
                                    (stride_qo - qk_k) * 2  // dstGap
                                );
                                SET_FLAG(MTE3, MTE2, EVENT_ID2);
                            }


                        }
                        else{
                            PIPE_BARRIER(V);
                            SET_FLAG(V, MTE3, EVENT_ID2);
                            WAIT_FLAG(V, MTE3, EVENT_ID2);
                            ub_to_gm<ArchType::ASCEND_V220, float>(
                                upo_gm_tensor[(uint64_t)block_idx * TMP_SIZE +  k_idx * TMP_SIZET +
                                        (uint64_t)sub_block_idx * qk_m / 2 * qk_round_k],
                                go_ubuf_tensor,
                                0,                                // sid
                                1,                                // nBurst
                                sub_m * qk_round_k / FLOAT_BLOCK_SIZE,  // lenBurst
                                0,                                // srcGap
                                0                                 // dstGap
                                );
                            SET_FLAG(MTE3, MTE2, EVENT_ID2);
                        }
                    }
                }
            }
        }
    }
    WAIT_FLAG(MTE3, MTE2, EVENT_ID0);
    WAIT_FLAG(MTE3, MTE2, EVENT_ID1);
    WAIT_FLAG(MTE3, MTE2, EVENT_ID2);
    WAIT_FLAG(V, MTE2, EVENT_ID0);
    WAIT_FLAG(V, MTE2, EVENT_ID1);
    WAIT_FLAG(V, MTE2, EVENT_ID2);
    WAIT_FLAG(V, MTE2, EVENT_ID3);
    WAIT_FLAG(V, MTE2, EVENT_ID4);
    WAIT_FLAG(V, MTE2, EVENT_ID5);
    WAIT_FLAG(MTE3, V, EVENT_ID0);
    WAIT_FLAG(MTE3, V, EVENT_ID1);
    PIPE_BARRIER(ALL);
}
#endif
