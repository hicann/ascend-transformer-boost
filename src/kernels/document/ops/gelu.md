# Gelu

## 参数说明

- **OpName**：ActivationOperation
- **PARAM**
  **Param Type**：OpParam::Activation

| 名称           | 类型 | 描述            |
| -------------- | ---- | --------------- |
| activationType | enum | ACTIVATION_GELU |

- **In/Out Tensor**

| 名称 | 类型 | dims                             | dtype                      | format |
| ---- | ---- | -------------------------------- | -------------------------- | ------ |
| x    | In   | [$d_0$, $d_1$, ..., $d_n$] | float32、float16、bfloat16 | ND     |
| y    | Out  | [$d_0$, $d_1$, ..., $d_n$] | 与x一致                    | ND     |

## 功能描述

- 算子功能：dropout的概率遵循正态分布，使激活变化会随机依赖于输入的大小。
- 计算公式：$y=0.5x(1+tanh[√(2/π)(x+0.044715x^3)])$

## 示例

```
输入：
     x = [[[ -5.605,  4.625,    3.498,   4.18],
           [-0.0689, -5.934,     4.22, -9.664]],
          [[   1.95, -2.385, -0.02238,  3.053],
           [   1.54,   7.41,   -2.986,  -5.53]]]
 
输出：
     y = [[[-0.0000e+00,  4.6250e+00,  3.4980e+00,  4.1797e+00],
           [-3.2562e-02, -0.0000e+00,  4.2188e+00, -0.0000e+00]],
          [[ 1.9004e+00, -1.9989e-02, -1.0994e-02,  3.0488e+00],
           [ 1.4443e+00,  7.4102e+00, -3.7994e-03, -0.0000e+00]]]
 
```

## 支持芯片型号

| 芯片名称   | 约束                   |
| ---------- | ---------------------- |
| ascend910b | 无                     |
| ascend310p | 不支持bfloat16数据类型 |
