# FastGelu

## 参数说明

- **OpName**：ActivationOperation
- **PARAM**
  **Param Type**：OpParam::Activation

| 名称           | 类型 | 描述                 |
| -------------- | ---- | -------------------- |
| activationType | enum | ACTIVATION_FAST_GELU |

- **In/Out Tensor**

| 名称 | 类型 | dims                             | dtype             | format |
| ---- | ---- | -------------------------------- | ----------------- | ------ |
| x    | In   | [$d_0$, $d_1$, ..., $d_n$] | bfloat16、float16 | ND     |
| y    | Out  | [$d_0$, $d_1$, ..., $d_n$] | 与x一致           | ND     |

## 功能描述

- 算子功能：快速运算的Gelu激活函数，对Tensor内每个element做Gelu激活函数近似计算，计算速度更快，同时保持较高的准确性。
- 计算公式：  
  $$
  \large
  y=\frac{x*e^{0.851(x-|x|)}}{1+e^{-1.702|x|}}
  $$

## 示例

```
输入：
	x = [[  -28.5, -9.30469, -6.61328, -14.3359, -9.38281, -14.7109, -11.1875,  -39.25],
		 [10.3594,  19.9375,  23.6094,  7.23438,  2.05664,  3.58398,  37.3438, 27.9062]]
 
输出：
	y = [[     -0, -1.13249, -8.55327,      -0, -1.13249,      -0,      -0,      -0],
		 [10.3594,  19.9375,  23.6094, 7.23438,  1.99609, 3.57617, 37.3438, 27.9062]]
 
```

## 支持芯片型号

| 芯片名称   | 约束                   |
| ---------- | ---------------------- |
| ascend910b | 无                     |
| ascend310p | 不支持bfloat16数据类型 |
