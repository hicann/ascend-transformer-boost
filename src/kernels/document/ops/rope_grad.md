# RopeGrad
## 参数说明
 
- **OpName**：RopeGradOperation
- **PARAM**
  **Param Type**：OpParam:RopeGrad
 
 
- **In/Out Tensor**
 
|  名称|  类型|  Dims|  dtype|  format  |
| ------------ | ------------ | ------------ | ------------ |------------ |
|  q       |  InTensor   |  [sum(qSeqLen), hiddenSize]|  float16  |ND| 
|  k       |  InTensor   |  [sum(qSeqLen), hiddenSize]|  float16  |ND| 
|  cos     |  InTensor   |  [maxSeqLen, headSize]|  float16  |ND| 
|  sin     |  InTensor   |  [maxSeqLen, headSize]|  float16  |ND| 
|  q_grad  |  OutTensor  |  [nTokens, hiddenSize]  |  float16  |  ND |
|  k_grad  |  OutTensor  |  [nTokens, hiddenSize]  |  float16  |  ND |
 
## 功能描述
 
- 算子功能：旋转位置编码处理的反向。
  max_seqlen是一个较大的长度, 每个batch的实际seqlen不会超过max_seqlen。
  hiddenSize为headSize的整倍数
  nTokens等于qSeqLen各值的平方和
 
## 示例
 
```
opPram（MIX_ROPE_GRAD=19）：
	{"mixType": 19,"batch":2,"qSeqLen":None}
 
输入：
q:  tensor([[0.6558, 0.6777, 0.9937,  ..., 0.8496, 0.4985, 0.7173],
            [0.7134, 0.6807, 0.7075,  ..., 0.9648, 0.2778, 0.9033],
            [0.6846, 0.6699, 0.7266,  ..., 0.7295, 0.0891, 0.2803],
            ...,
            [0.0370, 0.1489, 0.2546,  ..., 0.3455, 0.9824, 0.7251],
            [0.0848, 0.1934, 0.7622,  ..., 0.4614, 0.1024, 0.6528],
            [0.0907, 0.6816, 0.9023,  ..., 0.9194, 0.8091, 0.7778]],
             dtype=torch.float16)
 
k:  tensor([[0.2690, 0.6587, 0.0470,  ..., 0.1243, 0.7959, 0.4021],
            [0.1412, 0.2939, 0.8159,  ..., 0.5815, 0.4275, 0.5376],
            [0.5732, 0.8550, 0.4055,  ..., 0.6338, 0.7905, 0.8574],
            ...,
            [0.9229, 0.8223, 0.5073,  ..., 0.4463, 0.4038, 0.9873],
            [0.3362, 0.9521, 0.1666,  ..., 0.1136, 0.7812, 0.9102],
            [0.8389, 0.0793, 0.5264,  ..., 0.0164, 0.9053, 0.2896]],
             dtype=torch.float16)
 
cos:  tensor([[0.5620, 0.1261, 0.8955,  ..., 0.9712, 0.2610, 0.1740],
              [0.3916, 0.5381, 0.6108,  ..., 0.2195, 0.0495, 0.6255],
              [0.8560, 0.7144, 0.8789,  ..., 0.7739, 0.5762, 0.1716],
              ...,
              [0.4167, 0.4070, 0.4236,  ..., 0.1146, 0.2467, 0.3428],
              [0.0223, 0.5581, 0.7651,  ..., 0.4963, 0.7319, 0.9121],
              [0.0423, 0.1288, 0.1791,  ..., 0.6792, 0.0203, 0.8633]],
               dtype=torch.float16)
 
sin:  tensor([[0.8135, 0.9136, 0.3354,  ..., 0.9189, 0.0715, 0.7104],
              [0.5342, 0.5996, 0.1980,  ..., 0.8564, 0.3630, 0.7100],
              [0.5151, 0.7544, 0.8481,  ..., 0.7217, 0.8721, 0.0252],
              ...,
              [0.2469, 0.6084, 0.9282,  ..., 0.0848, 0.6089, 0.2231],
              [0.2954, 0.9141, 0.0074,  ..., 0.6172, 0.7251, 0.1003],
              [0.3057, 0.2576, 0.0797,  ..., 0.9868, 0.0427, 0.7183]],
               dtype=torch.float16)
 
 
输出：
q_grad:  tensor([[ 0.8760,  0.3174,  1.7598,  ...,  0.4480, -0.2170, -0.3384],
                 [ 0.3804,  0.6250,  0.8540,  ..., -0.2668, -0.2202,  0.3123],
                 [ 0.9224,  1.0537,  1.1221,  ...,  0.3240, -0.0080, -0.0768],
                 ...,
                 [ 0.0585,  0.1678,  0.3098,  ...,  0.1912,  0.1317,  0.0667],
                 [ 0.0943,  0.1785,  0.4861,  ..., -0.0880, -0.0765,  0.1763],
                 [ 0.0112,  0.7363,  1.0508,  ...,  0.2238, -0.1256,  0.0900]],
                  dtype=torch.float16)
                  
k_grad:  tensor([[ 0.3594,  0.3083,  0.0833,  ...,  0.0656, -0.3464, -0.1897],
                 [ 0.0753,  0.2698,  0.9849,  ..., -0.1609, -0.3389,  0.1858],
                 [ 0.7725,  1.3447,  0.6265,  ...,  0.2815, -0.0706, -0.2349],
                 ...,
                 [ 1.4600,  0.9268,  0.6172,  ...,  0.2469,  0.0541,  0.0909],
                 [ 0.3735,  0.8789,  0.1063,  ..., -0.0217, -0.5835,  0.2457],
                 [ 0.1035,  0.0857,  0.6133,  ...,  0.0040, -0.1406,  0.0335]],
                  dtype=torch.float16)
 
```
 
## 支持芯片型号
 
|芯片名称|约束 | 
| ------------ | ------------ | 
|  ascend910b|无 |